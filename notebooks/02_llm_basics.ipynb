{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89db49a6",
   "metadata": {},
   "source": [
    "# ü§ñ Notebook 02: LLM Basics - First API Calls\n",
    "\n",
    "**Time:** 15 minutes  \n",
    "**Goal:** Understand how to interact with LLMs and control their behavior\n",
    "\n",
    "In this notebook, you'll learn:\n",
    "- System vs User prompts\n",
    "- Temperature parameter (randomness control)\n",
    "- Max tokens (response length)\n",
    "- Cost tracking and optimization\n",
    "- Token estimation\n",
    "\n",
    "**Prerequisites:** Notebook 01 completed successfully\n",
    "\n",
    "Let's dive in! üöÄ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f1bf369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "NOTEBOOK 02: LLM BASICS\n",
      "============================================================\n",
      "\n",
      "Configuration loaded: Path A\n",
      "\n",
      "‚úì Claude API client initialized\n",
      "  Default model: claude-sonnet-4-5-20250929\n",
      "  Available: Opus 4.5, Sonnet 4.5, Haiku 4.5\n",
      "\n",
      "‚úì Ready to start!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Setup and Imports\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "# Add parent directory to path\n",
    "notebook_dir = os.getcwd()\n",
    "parent_dir = str(Path(notebook_dir).parent)\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.insert(0, parent_dir)\n",
    "\n",
    "# Load environment\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(os.path.join(parent_dir, '.env'))\n",
    "\n",
    "# Import our modules\n",
    "from src.llm_client import LLMClient\n",
    "from src.cost_tracker import CostTracker\n",
    "from src.utils import estimate_tokens, estimate_cost, format_response\n",
    "from src.config import PATH\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"NOTEBOOK 02: LLM BASICS\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "print(f\"Configuration loaded: Path {PATH}\")\n",
    "print()\n",
    "\n",
    "# Initialize client and tracker\n",
    "client = LLMClient(path=PATH)\n",
    "tracker = CostTracker()\n",
    "\n",
    "print()\n",
    "print(\"‚úì Ready to start!\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99eebd01",
   "metadata": {},
   "source": [
    "## üìö Understanding LLM Interactions\n",
    "\n",
    "When you communicate with an LLM, you're essentially having a conversation with specific controls:\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "**1. Prompts**\n",
    "- **User Prompt:** Your question or request (required)\n",
    "- **System Prompt:** Sets the AI's behavior and role (optional but powerful)\n",
    "\n",
    "**2. Temperature (0.0 - 1.0)**\n",
    "- **0.0** = Deterministic, consistent, factual\n",
    "- **0.5** = Balanced creativity and consistency  \n",
    "- **1.0** = Creative, varied, less predictable\n",
    "\n",
    "**3. Max Tokens**\n",
    "- Controls maximum response length\n",
    "- 1 token ‚âà 0.75 words (English)\n",
    "- Balance completeness vs cost\n",
    "\n",
    "Let's experiment! üß™"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b77217",
   "metadata": {},
   "source": [
    "---\n",
    "## üß™ Experiment 1: Basic User Prompt\n",
    "\n",
    "Let's start simple - just a user prompt with no special configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f83fa86b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "EXPERIMENT 1: Simple User Prompt\n",
      "============================================================\n",
      "\n",
      "Prompt: What is machine learning?\n",
      "\n",
      "Generating response...\n",
      "‚úì Success!\n",
      "\n",
      "Model: claude-sonnet-4-5-20250929\n",
      "Tokens: 12 in, 150 out\n",
      "\n",
      "Response:\n",
      "------------------------------------------------------------\n",
      "Machine learning is a branch of artificial intelligence (AI) where computers learn to make decisions or predictions from data without being explicitly programmed for every scenario.\n",
      "\n",
      "## Key Concepts:\n",
      "\n",
      "**How it works:**\n",
      "- Systems are fed large amounts of data\n",
      "- They identify patterns and relationships in that data\n",
      "- They use those patterns to make predictions or decisions about new data\n",
      "\n",
      "**Common examples:**\n",
      "- Email spam filters learning to identify unwanted messages\n",
      "- Netflix recommending shows based on your viewing history\n",
      "- Voice assistants understanding speech\n",
      "- Self-driving cars recognizing pedestrians and road signs\n",
      "\n",
      "**Main types:**\n",
      "1. **Supervised learning** - learning from labeled examples (like showing a system pictures labeled \"cat\"\n",
      "------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Simple User Prompt\n",
    "print(\"=\" * 60)\n",
    "print(\"EXPERIMENT 1: Simple User Prompt\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "\n",
    "prompt = \"What is machine learning?\"\n",
    "\n",
    "print(f\"Prompt: {prompt}\")\n",
    "print()\n",
    "print(\"Generating response...\")\n",
    "\n",
    "response = client.generate(\n",
    "    prompt=prompt,\n",
    "    temperature=0.7,\n",
    "    max_tokens=150\n",
    ")\n",
    "\n",
    "if \"error\" in response:\n",
    "    print(f\"‚ùå Error: {response['error']}\")\n",
    "else:\n",
    "    print(f\"‚úì Success!\")\n",
    "    print()\n",
    "    print(f\"Model: {response['model']}\")\n",
    "    print(f\"Tokens: {response['usage']['input_tokens']} in, {response['usage']['output_tokens']} out\")\n",
    "    print()\n",
    "    print(\"Response:\")\n",
    "    print(\"-\" * 60)\n",
    "    print(response['content'])\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    # Track cost\n",
    "    tracker.add_call(response)\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f639d8",
   "metadata": {},
   "source": [
    "### üí° Observation\n",
    "\n",
    "Notice how the response is straightforward and informative. The LLM used its default \"helpful assistant\" behavior.\n",
    "\n",
    "Now let's see what happens when we add a **system prompt** to control its behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdfd098",
   "metadata": {},
   "source": [
    "---\n",
    "## üß™ Experiment 2: Adding a System Prompt\n",
    "\n",
    "System prompts are incredibly powerful - they set the \"character\" and constraints of the AI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ee5d008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "EXPERIMENT 2: System Prompt Changes Everything\n",
      "============================================================\n",
      "\n",
      "System Prompt:\n",
      "You are a teacher explaining concepts to a 10-year-old child.\n",
      "Use simple words, fun examples, and keep explanations short and engaging.\n",
      "\n",
      "User Prompt: What is machine learning?\n",
      "\n",
      "Generating response...\n",
      "‚úì Success!\n",
      "\n",
      "Model: claude-sonnet-4-5-20250929\n",
      "Tokens: 44 in, 150 out\n",
      "\n",
      "Response:\n",
      "------------------------------------------------------------\n",
      "# Machine Learning is Teaching Computers to Learn!\n",
      "\n",
      "Imagine you're teaching your dog a new trick. You don't explain it in words - instead, you show examples! Give treats when they get it right, and they learn from practice.\n",
      "\n",
      "**Machine learning is similar, but for computers!**\n",
      "\n",
      "## Here's a fun example:\n",
      "\n",
      "Let's say you want a computer to recognize pictures of cats vs. dogs.\n",
      "\n",
      "**Old way (regular programming):** You'd have to write rules like \"if it has pointy ears and whiskers, it's a cat.\" But that's really hard because animals look so different!\n",
      "\n",
      "**Machine learning way:** You show the computer thousands of pictures - \"This is a cat,\n",
      "------------------------------------------------------------\n",
      "\n",
      "üí° Notice: Same question, VERY different answer!\n",
      "   The system prompt completely changed the tone and complexity.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# System Prompt Example\n",
    "print(\"=\" * 60)\n",
    "print(\"EXPERIMENT 2: System Prompt Changes Everything\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "\n",
    "system_prompt = \"\"\"You are a teacher explaining concepts to a 10-year-old child.\n",
    "Use simple words, fun examples, and keep explanations short and engaging.\"\"\"\n",
    "\n",
    "user_prompt = \"What is machine learning?\"\n",
    "\n",
    "print(\"System Prompt:\")\n",
    "print(system_prompt)\n",
    "print()\n",
    "print(f\"User Prompt: {user_prompt}\")\n",
    "print()\n",
    "print(\"Generating response...\")\n",
    "\n",
    "response = client.generate(\n",
    "    prompt=user_prompt,\n",
    "    system=system_prompt,\n",
    "    temperature=0.7,\n",
    "    max_tokens=150\n",
    ")\n",
    "\n",
    "if \"error\" in response:\n",
    "    print(f\"‚ùå Error: {response['error']}\")\n",
    "else:\n",
    "    print(f\"‚úì Success!\")\n",
    "    print()\n",
    "    print(f\"Model: {response['model']}\")\n",
    "    print(f\"Tokens: {response['usage']['input_tokens']} in, {response['usage']['output_tokens']} out\")\n",
    "    print()\n",
    "    print(\"Response:\")\n",
    "    print(\"-\" * 60)\n",
    "    print(response['content'])\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    tracker.add_call(response)\n",
    "\n",
    "print()\n",
    "print(\"üí° Notice: Same question, VERY different answer!\")\n",
    "print(\"   The system prompt completely changed the tone and complexity.\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8245b07",
   "metadata": {},
   "source": [
    "### üéØ Key Takeaway\n",
    "\n",
    "**System prompts are your primary tool for controlling LLM behavior.** They're more powerful than you might think!\n",
    "\n",
    "Common system prompt patterns:\n",
    "- **Role-based:** \"You are an expert Python programmer...\"\n",
    "- **Tone/Style:** \"You are friendly and encouraging...\"\n",
    "- **Constraints:** \"Always respond in JSON format...\"\n",
    "- **Domain:** \"You are a medical research assistant...\"\n",
    "\n",
    "We'll explore these more in Notebook 03 (CO-STAR Framework)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1f63e7",
   "metadata": {},
   "source": [
    "---\n",
    "## üå°Ô∏è Experiment 3: Temperature Control\n",
    "\n",
    "Temperature controls randomness. Let's ask the same question 3 times with different temperatures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6965159a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "EXPERIMENT 3: Temperature Effects\n",
      "============================================================\n",
      "\n",
      "Temperature: 0.0\n",
      "------------------------------------------------------------\n",
      "Here's a fun fact: **Neptune has the fastest winds in the solar system**, with speeds reaching up to 1,200 mph (2,000 km/h) ‚Äî that's faster than the speed of sound! \n",
      "\n",
      "What makes this extra surprising is that Neptune is the farthest planet from the Sun and receives very little solar energy, yet somehow it generates these incredibly powerful winds. Scientists think the planet must have a strong internal heat source driving its wild weather.\n",
      "\n",
      "Temperature: 0.5\n",
      "------------------------------------------------------------\n",
      "Here's a fun space fact: **Neptune has supersonic winds!** \n",
      "\n",
      "The winds on Neptune can reach speeds of up to 1,200 mph (2,000 km/h) ‚Äî that's faster than the speed of sound. These are the strongest winds ever detected in our solar system, even though Neptune is the farthest planet from the Sun and receives very little solar energy. Scientists still aren't entirely sure what powers these incredibly fast winds! üå™\n",
      "\n",
      "Temperature: 1.0\n",
      "------------------------------------------------------------\n",
      "Here's a fun space fact: **Venus rotates so slowly that a single day on Venus (one complete rotation) takes 243 Earth days ‚Äî which is actually longer than a Venusian year, which only takes 225 Earth days!**\n",
      "\n",
      "This means that on Venus, a day is longer than a year. Even stranger, Venus rotates backwards compared to most planets, so the Sun rises in the west and sets in the east. üåÖ\n",
      "\n",
      "\n",
      "============================================================\n",
      "ANALYSIS\n",
      "============================================================\n",
      "\n",
      "üí° Observations:\n",
      "\n",
      "Temperature 0.0 (Deterministic):\n",
      "  ‚Ä¢ Should give same/similar answer if you run it twice\n",
      "  ‚Ä¢ Best for factual, consistent responses\n",
      "  ‚Ä¢ Use for: classification, extraction, structured output\n",
      "\n",
      "Temperature 0.5 (Balanced):\n",
      "  ‚Ä¢ Good balance of creativity and consistency\n",
      "  ‚Ä¢ Most versatile setting\n",
      "  ‚Ä¢ Use for: general Q&A, explanations, summaries\n",
      "\n",
      "Temperature 1.0 (Creative):\n",
      "  ‚Ä¢ More varied and creative responses\n",
      "  ‚Ä¢ Less predictable\n",
      "  ‚Ä¢ Use for: creative writing, brainstorming, variety\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Temperature Comparison\n",
    "print(\"=\" * 60)\n",
    "print(\"EXPERIMENT 3: Temperature Effects\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "\n",
    "prompt = \"Tell me a fun fact about space.\"\n",
    "\n",
    "temperatures = [0.0, 0.5, 1.0]\n",
    "\n",
    "results = []\n",
    "\n",
    "for temp in temperatures:\n",
    "    print(f\"Temperature: {temp}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    response = client.generate(\n",
    "        prompt=prompt,\n",
    "        temperature=temp,\n",
    "        max_tokens=100\n",
    "    )\n",
    "    \n",
    "    if \"error\" not in response:\n",
    "        print(response['content'])\n",
    "        results.append(response['content'])\n",
    "        tracker.add_call(response)\n",
    "    else:\n",
    "        print(f\"Error: {response['error']}\")\n",
    "    \n",
    "    print()\n",
    "    time.sleep(0.5)  # Small delay to avoid rate limits\n",
    "\n",
    "print()\n",
    "print(\"=\" * 60)\n",
    "print(\"ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "print(\"üí° Observations:\")\n",
    "print()\n",
    "print(\"Temperature 0.0 (Deterministic):\")\n",
    "print(\"  ‚Ä¢ Should give same/similar answer if you run it twice\")\n",
    "print(\"  ‚Ä¢ Best for factual, consistent responses\")\n",
    "print(\"  ‚Ä¢ Use for: classification, extraction, structured output\")\n",
    "print()\n",
    "print(\"Temperature 0.5 (Balanced):\")\n",
    "print(\"  ‚Ä¢ Good balance of creativity and consistency\")\n",
    "print(\"  ‚Ä¢ Most versatile setting\")\n",
    "print(\"  ‚Ä¢ Use for: general Q&A, explanations, summaries\")\n",
    "print()\n",
    "print(\"Temperature 1.0 (Creative):\")\n",
    "print(\"  ‚Ä¢ More varied and creative responses\")\n",
    "print(\"  ‚Ä¢ Less predictable\")\n",
    "print(\"  ‚Ä¢ Use for: creative writing, brainstorming, variety\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85317134",
   "metadata": {},
   "source": [
    "### üé≤ Understanding Temperature\n",
    "\n",
    "Think of temperature like this:\n",
    "```\n",
    "Temperature 0.0\n",
    "‚îî‚îÄ> Always picks the most likely next word\n",
    "    ‚îî‚îÄ> Consistent, predictable, \"safe\"\n",
    "\n",
    "Temperature 1.0\n",
    "‚îî‚îÄ> Considers many possibilities\n",
    "    ‚îî‚îÄ> Creative, varied, surprising\n",
    "```\n",
    "\n",
    "**Rule of Thumb:**\n",
    "- Factual tasks? ‚Üí Temperature 0.0-0.3\n",
    "- General tasks? ‚Üí Temperature 0.5-0.7  \n",
    "- Creative tasks? ‚Üí Temperature 0.8-1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05ff44c",
   "metadata": {},
   "source": [
    "---\n",
    "## üìè Experiment 4: Max Tokens (Response Length)\n",
    "\n",
    "Max tokens controls how long the response can be. Let's see it in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebfdac7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "EXPERIMENT 4: Max Tokens Controls Length\n",
      "============================================================\n",
      "\n",
      "Max Tokens: 50\n",
      "------------------------------------------------------------\n",
      "Actual output tokens: 50\n",
      "Stop reason: max_tokens\n",
      "\n",
      "# Benefits of Regular Exercise\n",
      "\n",
      "## Physical Health\n",
      "- **Cardiovascular health**: Strengthens your heart and improves circulation, reducing risk of heart disease and stroke\n",
      "- **Weight management**: Burns calories and builds muscle, helping maintain a healthy\n",
      "\n",
      "‚ö†Ô∏è  Response was CUT OFF (hit token limit)\n",
      "\n",
      "\n",
      "Max Tokens: 150\n",
      "------------------------------------------------------------\n",
      "Actual output tokens: 150\n",
      "Stop reason: max_tokens\n",
      "\n",
      "# Benefits of Regular Exercise\n",
      "\n",
      "## Physical Health\n",
      "- **Cardiovascular health**: Strengthens your heart and improves circulation, reducing risk of heart disease and stroke\n",
      "- **Weight management**: Burns calories and builds muscle, helping maintain a healthy weight\n",
      "- **Stronger bones and muscles**: Reduces age-related decline and lowers osteoporosis risk\n",
      "- **Disease prevention**: Decreases risk of type 2 diabetes, certain cancers, and metabolic syndrome\n",
      "- **Enhanced immune function**: Helps your body fight off illnesses more effectively\n",
      "\n",
      "## Mental Health\n",
      "- **Reduced stress and anxiety**: Lowers cortisol levels and promotes relaxation\n",
      "- **Improved mood**: Releases end\n",
      "\n",
      "‚ö†Ô∏è  Response was CUT OFF (hit token limit)\n",
      "\n",
      "\n",
      "Max Tokens: 500\n",
      "------------------------------------------------------------\n",
      "Actual output tokens: 332\n",
      "Stop reason: end_turn\n",
      "\n",
      "# Benefits of Regular Exercise\n",
      "\n",
      "## Physical Health\n",
      "- **Cardiovascular health**: Strengthens your heart and improves circulation, reducing risk of heart disease and stroke\n",
      "- **Weight management**: Burns calories and builds muscle, helping maintain a healthy body weight\n",
      "- **Stronger bones and muscles**: Reduces risk of osteoporosis and maintains muscle mass as you age\n",
      "- **Better immune function**: Helps your body fight off illnesses more effectively\n",
      "- **Chronic disease prevention**: Lowers risk of type 2 diabetes, certain cancers, and metabolic syndrome\n",
      "\n",
      "## Mental Health\n",
      "- **Reduced stress and anxiety**: Releases endorphins that naturally improve mood\n",
      "- **Better sleep quality**: Helps you fall asleep faster and sleep more deeply\n",
      "- **Improved cognitive function**: Enhances memory, focus, and mental clarity\n",
      "- **Depression relief**: Can be as effective as medication for mild to moderate depression\n",
      "- **Increased self-esteem**: Achieving fitness goals boosts confidence\n",
      "\n",
      "## Daily Life Benefits\n",
      "- **More energy**: Paradoxically, expending energy through exercise gives you more throughout the day\n",
      "- **Enhanced productivity**: Better focus and mental stamina for work and tasks\n",
      "- **Increased longevity**: Regular exercisers tend to live longer, healthier lives\n",
      "- **Social connections**: Group activities and classes provide opportunities to meet people\n",
      "\n",
      "## Recommended Amount\n",
      "Aim for at least **150 minutes of moderate activity** or **75 minutes of vigorous activity** per week, plus strength training twice weekly.\n",
      "\n",
      "‚úì Response completed naturally\n",
      "\n",
      "\n",
      "üí° Notice:\n",
      "  ‚Ä¢ 50 tokens: Likely incomplete (stopped mid-sentence)\n",
      "  ‚Ä¢ 150 tokens: Might be complete, might not\n",
      "  ‚Ä¢ 500 tokens: Definitely complete (finished naturally)\n",
      "\n",
      "  Check 'stop_reason' to know if response was cut off!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Max Tokens Comparison\n",
    "print(\"=\" * 60)\n",
    "print(\"EXPERIMENT 4: Max Tokens Controls Length\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "\n",
    "prompt = \"Explain the benefits of regular exercise.\"\n",
    "\n",
    "token_limits = [50, 150, 500]\n",
    "\n",
    "for max_tok in token_limits:\n",
    "    print(f\"Max Tokens: {max_tok}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    response = client.generate(\n",
    "        prompt=prompt,\n",
    "        temperature=0.7,\n",
    "        max_tokens=max_tok\n",
    "    )\n",
    "    \n",
    "    if \"error\" not in response:\n",
    "        print(f\"Actual output tokens: {response['usage']['output_tokens']}\")\n",
    "        print(f\"Stop reason: {response['stop_reason']}\")\n",
    "        print()\n",
    "        print(response['content'])\n",
    "        print()\n",
    "        \n",
    "        # Check if it was cut off\n",
    "        if response['stop_reason'] == 'max_tokens':\n",
    "            print(\"‚ö†Ô∏è  Response was CUT OFF (hit token limit)\")\n",
    "        else:\n",
    "            print(\"‚úì Response completed naturally\")\n",
    "        \n",
    "        tracker.add_call(response)\n",
    "    else:\n",
    "        print(f\"Error: {response['error']}\")\n",
    "    \n",
    "    print()\n",
    "    print()\n",
    "    time.sleep(0.5)\n",
    "\n",
    "print(\"üí° Notice:\")\n",
    "print(\"  ‚Ä¢ 50 tokens: Likely incomplete (stopped mid-sentence)\")\n",
    "print(\"  ‚Ä¢ 150 tokens: Might be complete, might not\")\n",
    "print(\"  ‚Ä¢ 500 tokens: Definitely complete (finished naturally)\")\n",
    "print()\n",
    "print(\"  Check 'stop_reason' to know if response was cut off!\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd21ded",
   "metadata": {},
   "source": [
    "### üìê Token Math\n",
    "\n",
    "Quick reference:\n",
    "- **1 token** ‚âà 4 characters (English)\n",
    "- **1 token** ‚âà 0.75 words (English)\n",
    "- **100 tokens** ‚âà 75 words\n",
    "- **500 tokens** ‚âà 375 words (about 1 paragraph)\n",
    "- **1000 tokens** ‚âà 750 words (about 1-2 pages)\n",
    "\n",
    "**Pro Tip:** Set `max_tokens` higher than you think you need, then the model will stop naturally when done. Better than cutting off mid-thought!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a6b1f5",
   "metadata": {},
   "source": [
    "---\n",
    "## üé≠ Experiment 5: System Prompt Patterns\n",
    "\n",
    "Let's explore different system prompt patterns for the same question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d55dad0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "EXPERIMENT 5: System Prompt Patterns\n",
      "============================================================\n",
      "\n",
      "üé≠ Role: Expert Programmer\n",
      "============================================================\n",
      "# How to Learn Python Programming\n",
      "\n",
      "Here's a practical, proven roadmap:\n",
      "\n",
      "## 1. **Start with Fundamentals (2-4 weeks)**\n",
      "- **Variables, data types** (strings, integers, lists, dictionaries)\n",
      "- **Control flow** (if/else, loops)\n",
      "- **Functions** and basic input/output\n",
      "- **Recommended free resources:**\n",
      "  - [Python.org's official tutorial](https://docs.python.org/3/tutorial/)\n",
      "  - [Automate the Boring Stuff with Python](https://automatetheboringstuff.com/) (free online)\n",
      "\n",
      "## 2. **Learn by Building (Ongoing)**\n",
      "Don't just read‚Äîcode daily. Start with:\n",
      "- **Simple projects:** Calculator, to-do list, number guessing game\n",
      "- **Practical scripts:** File renamer, web scraper, data analyzer\n",
      "- **Gradually\n",
      "\n",
      "\n",
      "üé≠ Role: Friendly Tutor\n",
      "============================================================\n",
      "Great choice! Python is one of the best languages for beginners. Here's a practical roadmap:\n",
      "\n",
      "## Start with the Basics (2-4 weeks)\n",
      "- **Variables & data types** (strings, numbers, lists)\n",
      "- **Control flow** (if/else, loops)\n",
      "- **Functions**\n",
      "- Try: [python.org](https://python.org) tutorial or Codecademy\n",
      "\n",
      "## Practice Daily (Key!)\n",
      "Think of it like learning an instrument - 30 minutes daily beats 3 hours once a week.\n",
      "\n",
      "**Easy practice ideas:**\n",
      "- Calculate your age in days\n",
      "- Build a simple calculator\n",
      "- Create a guessing game\n",
      "\n",
      "## Build Small Projects (1-2 months)\n",
      "- To-do list app\n",
      "- Web scraper\n",
      "- Simple chatbot\n",
      "\n",
      "## Resources I recommend:\n",
      "- **\"Automate the Boring Stuff\"** (free book) - super\n",
      "\n",
      "\n",
      "üé≠ Role: Structured Coach\n",
      "============================================================\n",
      "# Learning Python Programming\n",
      "\n",
      "## 1. Quick Answer\n",
      "Start with Python basics through interactive platforms like Codecademy or freeCodeCamp, then build small projects to practice what you learn.\n",
      "\n",
      "## 2. Step-by-Step Breakdown\n",
      "\n",
      "**Step 1: Master the Fundamentals (2-4 weeks)**\n",
      "- Learn variables, data types, loops, and functions\n",
      "- Use free resources: Python.org tutorial, Codecademy, or SoloLearn app\n",
      "- Practice daily for 30-60 minutes\n",
      "\n",
      "**Step 2: Build Simple Projects (4-6 weeks)**\n",
      "- Create a calculator, to-do list, or simple game\n",
      "- Work through beginner projects on GitHub or follow YouTube tutorials\n",
      "- Focus on applying concepts, not just reading about them\n",
      "\n",
      "**Step 3: Learn Key Libraries & Tools (ongoing)**\n",
      "- Explore libraries based on your interest: pandas (data),\n",
      "\n",
      "\n",
      "üé≠ Role: Socratic Teacher\n",
      "============================================================\n",
      "Great question! Let me help you discover your own path to learning Python. First, let me ask you a few things:\n",
      "\n",
      "**What's drawing you to Python?** Is there a specific problem you want to solve, a project you have in mind, or a field you're interested in (like data science, web development, automation, etc.)?\n",
      "\n",
      "**What's your current experience with programming?** Have you coded before in any language, or is this your first venture into programming?\n",
      "\n",
      "Also, think about this: **How do you learn best?** \n",
      "- Do you prefer learning by doing hands-on projects?\n",
      "- Do you like structured lessons with clear steps?\n",
      "- Do you learn better by reading, watching videos, or experimenting?\n",
      "\n",
      "Once we understand your goals and learning style, what do you think would be a logical first step? What resources or approaches come to mind when you think about learning a new skill?\n",
      "\n",
      "\n",
      "üí° Key Insight:\n",
      "   The SAME question got 4 completely different styles of answers!\n",
      "   System prompts are your most powerful control mechanism.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# System Prompt Pattern Library\n",
    "print(\"=\" * 60)\n",
    "print(\"EXPERIMENT 5: System Prompt Patterns\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "\n",
    "user_prompt = \"How do I learn Python programming?\"\n",
    "\n",
    "system_prompts = {\n",
    "    \"Expert Programmer\": \"\"\"You are an expert Python programmer with 10 years of experience.\n",
    "You write clean, efficient, well-documented code. Give practical, actionable advice.\"\"\",\n",
    "    \n",
    "    \"Friendly Tutor\": \"\"\"You are a friendly programming tutor who loves teaching beginners.\n",
    "You explain concepts clearly, use analogies, and are always encouraging. \n",
    "Keep responses concise but helpful.\"\"\",\n",
    "    \n",
    "    \"Structured Coach\": \"\"\"You are a structured learning coach.\n",
    "Always provide responses in this exact format:\n",
    "1. Quick answer (1 sentence)\n",
    "2. Step-by-step breakdown (3-4 steps)\n",
    "3. One actionable tip for today\"\"\",\n",
    "    \n",
    "    \"Socratic Teacher\": \"\"\"You are a Socratic teacher who guides students to discover answers.\n",
    "Instead of giving direct answers, ask thought-provoking questions.\n",
    "Help the student think through the problem themselves.\"\"\"\n",
    "}\n",
    "\n",
    "for role, system in system_prompts.items():\n",
    "    print(f\"üé≠ Role: {role}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    response = client.generate(\n",
    "        prompt=user_prompt,\n",
    "        system=system,\n",
    "        temperature=0.7,\n",
    "        max_tokens=200\n",
    "    )\n",
    "    \n",
    "    if \"error\" not in response:\n",
    "        print(response['content'])\n",
    "        tracker.add_call(response)\n",
    "    else:\n",
    "        print(f\"Error: {response['error']}\")\n",
    "    \n",
    "    print()\n",
    "    print()\n",
    "    time.sleep(0.5)\n",
    "\n",
    "print(\"üí° Key Insight:\")\n",
    "print(\"   The SAME question got 4 completely different styles of answers!\")\n",
    "print(\"   System prompts are your most powerful control mechanism.\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1764e686",
   "metadata": {},
   "source": [
    "### üé® System Prompt Design Tips\n",
    "\n",
    "**Good System Prompts:**\n",
    "- ‚úÖ Are specific and clear\n",
    "- ‚úÖ Define role/expertise\n",
    "- ‚úÖ Set tone and style\n",
    "- ‚úÖ Include constraints if needed\n",
    "- ‚úÖ Are concise (don't waste tokens)\n",
    "\n",
    "**Avoid:**\n",
    "- ‚ùå Being too vague\n",
    "- ‚ùå Contradictory instructions\n",
    "- ‚ùå Unnecessary details\n",
    "- ‚ùå Asking for impossible things"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183af912",
   "metadata": {},
   "source": [
    "---\n",
    "## üí∞ Cost Tracking & Optimization\n",
    "\n",
    "Let's look at how much we've spent so far and learn cost optimization strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "147e36fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "COST TRACKING REPORT\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "üí∞ API COST REPORT\n",
      "============================================================\n",
      "Total API calls: 12\n",
      "Total input tokens: 362\n",
      "Total output tokens: 1,928\n",
      "Total cost: $0.0300\n",
      "\n",
      "All calls:\n",
      "  1. [00:44:05] sonnet - 12in/150out - $0.0023\n",
      "  2. [00:45:22] sonnet - 44in/150out - $0.0024\n",
      "  3. [00:47:38] sonnet - 15in/100out - $0.0015\n",
      "  4. [00:47:42] sonnet - 15in/100out - $0.0015\n",
      "  5. [00:47:46] sonnet - 15in/100out - $0.0015\n",
      "  6. [00:48:44] sonnet - 15in/50out - $0.0008\n",
      "  7. [00:48:48] sonnet - 15in/150out - $0.0023\n",
      "  8. [00:49:01] sonnet - 15in/332out - $0.0050\n",
      "  9. [00:49:58] sonnet - 47in/200out - $0.0031\n",
      "  10. [00:50:04] sonnet - 51in/200out - $0.0032\n",
      "  11. [00:50:11] sonnet - 65in/200out - $0.0032\n",
      "  12. [00:50:16] sonnet - 53in/196out - $0.0031\n",
      "============================================================\n",
      "\n",
      "üí° Cost Optimization Tips:\n",
      "\n",
      "1. Use appropriate models:\n",
      "   ‚Ä¢ Haiku for simple tasks (5x cheaper than Sonnet)\n",
      "   ‚Ä¢ Sonnet for complex reasoning\n",
      "   ‚Ä¢ Opus only when you need the absolute best\n",
      "\n",
      "2. Control response length:\n",
      "   ‚Ä¢ Use lower max_tokens when possible\n",
      "   ‚Ä¢ Ask for 'concise' or 'brief' answers\n",
      "\n",
      "3. Optimize prompts:\n",
      "   ‚Ä¢ Be clear and direct (avoid rambling)\n",
      "   ‚Ä¢ Remove unnecessary context\n",
      "   ‚Ä¢ But don't sacrifice clarity!\n",
      "\n",
      "4. Use temperature wisely:\n",
      "   ‚Ä¢ Lower temperature = more efficient\n",
      "   ‚Ä¢ Use 0.0 for deterministic tasks\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cost Report\n",
    "print(\"=\" * 60)\n",
    "print(\"COST TRACKING REPORT\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "\n",
    "tracker.report(detailed=True)\n",
    "\n",
    "print()\n",
    "print(\"üí° Cost Optimization Tips:\")\n",
    "print()\n",
    "print(\"1. Use appropriate models:\")\n",
    "print(\"   ‚Ä¢ Haiku for simple tasks (5x cheaper than Sonnet)\")\n",
    "print(\"   ‚Ä¢ Sonnet for complex reasoning\")\n",
    "print(\"   ‚Ä¢ Opus only when you need the absolute best\")\n",
    "print()\n",
    "print(\"2. Control response length:\")\n",
    "print(\"   ‚Ä¢ Use lower max_tokens when possible\")\n",
    "print(\"   ‚Ä¢ Ask for 'concise' or 'brief' answers\")\n",
    "print()\n",
    "print(\"3. Optimize prompts:\")\n",
    "print(\"   ‚Ä¢ Be clear and direct (avoid rambling)\")\n",
    "print(\"   ‚Ä¢ Remove unnecessary context\")\n",
    "print(\"   ‚Ä¢ But don't sacrifice clarity!\")\n",
    "print()\n",
    "print(\"4. Use temperature wisely:\")\n",
    "print(\"   ‚Ä¢ Lower temperature = more efficient\")\n",
    "print(\"   ‚Ä¢ Use 0.0 for deterministic tasks\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ef0e96",
   "metadata": {},
   "source": [
    "### üí∏ Real Cost Analysis\n",
    "\n",
    "Let's calculate actual costs for common tasks:\n",
    "\n",
    "**Example: Summarizing a document**\n",
    "- Input: 2000 tokens (document)\n",
    "- Output: 200 tokens (summary)\n",
    "- Model: Sonnet 4.5\n",
    "\n",
    "Cost = (2000/1M √ó $3) + (200/1M √ó $15) = $0.006 + $0.003 = **$0.009**\n",
    "\n",
    "About **1 cent** per document! \n",
    "\n",
    "**For this homework (using Sonnet):**\n",
    "- Expected: 50-100 API calls\n",
    "- Average: 100 input + 150 output tokens\n",
    "- Total cost: ~$1-2\n",
    "\n",
    "**Money-saving tip:** Use Ollama (free) for learning, Claude for final deliverables!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "348ba97f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TOKEN ESTIMATION TOOL\n",
      "============================================================\n",
      "\n",
      "Comparing prompt lengths:\n",
      "\n",
      "Short Prompt:\n",
      "  Characters: 11\n",
      "  Words: 3\n",
      "  Est. tokens: 2\n",
      "  Est. cost (with 150 token response): $0.002256\n",
      "\n",
      "Medium Prompt:\n",
      "  Characters: 105\n",
      "  Words: 18\n",
      "  Est. tokens: 26\n",
      "  Est. cost (with 150 token response): $0.002328\n",
      "\n",
      "Long Prompt:\n",
      "  Characters: 317\n",
      "  Words: 48\n",
      "  Est. tokens: 79\n",
      "  Est. cost (with 150 token response): $0.002487\n",
      "\n",
      "üí° Lesson: Concise prompts save money, but don't sacrifice clarity!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Token Estimation Tool\n",
    "print(\"=\" * 60)\n",
    "print(\"TOKEN ESTIMATION TOOL\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "\n",
    "# Test different prompt lengths\n",
    "test_prompts = {\n",
    "    \"Short\": \"What is AI?\",\n",
    "    \"Medium\": \"Can you explain what artificial intelligence is and give some examples of how it's used in everyday life?\",\n",
    "    \"Long\": \"\"\"I'm interested in learning about artificial intelligence. Could you please provide \n",
    "a comprehensive explanation of what AI is, how it works at a high level, what the different types \n",
    "of AI are, and some real-world applications? I'm particularly interested in understanding machine \n",
    "learning and deep learning as well.\"\"\"\n",
    "}\n",
    "\n",
    "print(\"Comparing prompt lengths:\")\n",
    "print()\n",
    "\n",
    "for label, prompt in test_prompts.items():\n",
    "    tokens = estimate_tokens(prompt)\n",
    "    words = len(prompt.split())\n",
    "    chars = len(prompt)\n",
    "    cost = estimate_cost(prompt, output_tokens=150, model=client.default_model)\n",
    "    \n",
    "    print(f\"{label} Prompt:\")\n",
    "    print(f\"  Characters: {chars}\")\n",
    "    print(f\"  Words: {words}\")\n",
    "    print(f\"  Est. tokens: {tokens}\")\n",
    "    print(f\"  Est. cost (with 150 token response): ${cost:.6f}\")\n",
    "    print()\n",
    "\n",
    "print(\"üí° Lesson: Concise prompts save money, but don't sacrifice clarity!\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be86ce99",
   "metadata": {},
   "source": [
    "---\n",
    "## üéØ Your Turn: Practice Tasks\n",
    "\n",
    "Now it's your turn to experiment! Complete these tasks to reinforce your learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665f8584",
   "metadata": {},
   "source": [
    "### üìù Task 1: Create a Custom System Prompt\n",
    "\n",
    "Design a system prompt for a specific use case you care about.\n",
    "\n",
    "**Ideas:**\n",
    "- Code reviewer\n",
    "- Creative story writer\n",
    "- Data analyst\n",
    "- Language tutor\n",
    "- Career advisor\n",
    "- Fitness coach\n",
    "- Study buddy\n",
    "\n",
    "**Requirements:**\n",
    "- Define clear role/expertise\n",
    "- Set appropriate tone\n",
    "- Include any constraints\n",
    "- Test it with a relevant question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59dcd059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - Task 1: Your Custom System Prompt\n",
    "from src.utils import append_to_reflection\n",
    "\n",
    "# ============================================================================\n",
    "# TODO: Fill in your system prompt and test prompt below\n",
    "# ============================================================================\n",
    "\n",
    "my_system_prompt = \"\"\"\n",
    "You are a professional code reviewer with expertise in Python.\n",
    "You provide constructive feedback, identify bugs, and suggest improvements.\n",
    "Be thorough but concise. Focus on: correctness, efficiency, and readability.\n",
    "\"\"\"\n",
    "\n",
    "my_user_prompt = \"\"\"\n",
    "Review this Python function:\n",
    "\n",
    "def calculate_average(numbers):\n",
    "    return sum(numbers) / len(numbers)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "150fb862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System Prompt Preview:\n",
      "------------------------------------------------------------\n",
      "You are a professional code reviewer with expertise in Python.\n",
      "You provide constructive feedback, identify bugs, and suggest improvements.\n",
      "Be thorough but concise. Focus on: correctness, efficiency, and readability.\n",
      "\n",
      "User Prompt Preview:\n",
      "------------------------------------------------------------\n",
      "Review this Python function:\n",
      "\n",
      "def calculate_average(numbers):\n",
      "    return sum(numbers) / len(numbers)\n",
      "\n",
      "Generating response...\n",
      "\n",
      "‚úÖ Response generated successfully!\n",
      "\n",
      "Response:\n",
      "============================================================\n",
      "## Code Review: `calculate_average` Function\n",
      "\n",
      "### Issues Identified\n",
      "\n",
      "**1. Missing Error Handling (Critical)**\n",
      "The function will raise exceptions in several scenarios:\n",
      "- **`ZeroDivisionError`**: When `numbers` is an empty list/iterable\n",
      "- **`TypeError`**: When `numbers` is `None` or contains non-numeric values\n",
      "\n",
      "### Recommendations\n",
      "\n",
      "```python\n",
      "def calculate_average(numbers):\n",
      "    \"\"\"\n",
      "    Calculate the arithmetic mean of a list of numbers.\n",
      "    \n",
      "    Args:\n",
      "        numbers: An iterable of numeric values\n",
      "        \n",
      "    Returns:\n",
      "        float: The average of the numbers\n",
      "        \n",
      "    Raises:\n",
      "        ValueError: If numbers is empty or None\n",
      "        TypeError: If numbers contains non-numeric values\n",
      "    \"\"\"\n",
      "    if not numbers:\n",
      "        raise ValueError(\"Cannot calculate average of empty sequence\")\n",
      "    \n",
      "    return sum(numbers) / len(numbers)\n",
      "```\n",
      "\n",
      "### Alternative Approaches\n",
      "\n",
      "**For better robustness:**\n",
      "```python\n",
      "def calculate_average(numbers):\n",
      "    \"\"\"Calculate average, returning None for empty sequences.\"\"\"\n",
      "    if not numbers:\n",
      "        return None\n",
      "    return sum(numbers) / len(numbers)\n",
      "```\n",
      "\n",
      "**For large datasets (memory efficient):**\n",
      "```python\n",
      "def calculate_average(numbers):\n",
      "    \"\"\"Calculate average without loading all numbers into memory.\"\"\"\n",
      "============================================================\n",
      "\n",
      "üìä Tokens: 80 in, 300 out\n",
      "\n",
      "============================================================\n",
      "REFLECTION\n",
      "============================================================\n",
      "\n",
      "\n",
      "### What I Learned\n",
      "\n",
      "[What did you learn from creating a custom system prompt?]\n",
      "\n",
      "### How the System Prompt Affected the Response\n",
      "\n",
      "[How did your system prompt change the response compared to no system prompt?]\n",
      "\n",
      "### Real-World Applications\n",
      "\n",
      "[Where would you use this type of system prompt in practice?]\n",
      "\n",
      "\n",
      "üíæ Reflection appended to: homework_reflection.md\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# Run this cell to generate response\n",
    "# ============================================================================\n",
    "\n",
    "print(\"System Prompt Preview:\")\n",
    "print(\"-\" * 60)\n",
    "print(my_system_prompt.strip())\n",
    "print()\n",
    "print(\"User Prompt Preview:\")\n",
    "print(\"-\" * 60)\n",
    "print(my_user_prompt.strip())\n",
    "print()\n",
    "print(\"Generating response...\")\n",
    "print()\n",
    "\n",
    "response = client.generate(\n",
    "    prompt=my_user_prompt,\n",
    "    system=my_system_prompt,\n",
    "    temperature=0.7,\n",
    "    max_tokens=300\n",
    ")\n",
    "\n",
    "if \"error\" not in response:\n",
    "    print(\"‚úÖ Response generated successfully!\")\n",
    "    print()\n",
    "    print(\"Response:\")\n",
    "    print(\"=\" * 60)\n",
    "    print(response['content'])\n",
    "    print(\"=\" * 60)\n",
    "    print()\n",
    "    print(f\"üìä Tokens: {response['usage']['input_tokens']} in, {response['usage']['output_tokens']} out\")\n",
    "    \n",
    "    # Track cost\n",
    "    tracker.add_call(response)\n",
    "    \n",
    "    print()\n",
    "    print(\"=\" * 60)\n",
    "    print(\"REFLECTION\")\n",
    "    print(\"=\" * 60)\n",
    "    print()\n",
    "    \n",
    "    # ========================================================================\n",
    "    # TODO: Fill in your reflection after seeing the response\n",
    "    # ========================================================================\n",
    "    \n",
    "    reflection = \"\"\"\n",
    "### What I Learned\n",
    "\n",
    "[What did you learn from creating a custom system prompt?]\n",
    "\n",
    "### How the System Prompt Affected the Response\n",
    "\n",
    "[How did your system prompt change the response compared to no system prompt?]\n",
    "\n",
    "### Real-World Applications\n",
    "\n",
    "[Where would you use this type of system prompt in practice?]\n",
    "\"\"\"\n",
    "    \n",
    "    print(reflection)\n",
    "    print()\n",
    "    \n",
    "    # Save to consolidated reflection file\n",
    "    reflection_file = append_to_reflection(\n",
    "        notebook=\"02\",\n",
    "        section_title=\"Task 1 - Custom System Prompt\",\n",
    "        reflection_content=reflection,\n",
    "        output_dir=os.path.join(parent_dir, 'outputs')\n",
    "    )\n",
    "    \n",
    "    print(f\"üíæ Reflection appended to: {os.path.basename(reflection_file)}\")\n",
    "    \n",
    "else:\n",
    "    print(f\"‚ùå Error: {response['error']}\")\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f44af9b",
   "metadata": {},
   "source": [
    "### üìù Task 2: Temperature Exploration\n",
    "\n",
    "Experiment with temperature to see how it affects creative tasks.\n",
    "\n",
    "**Goal:** Find the right temperature for different task types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81ea43cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TASK 2: Temperature Exploration\n",
      "============================================================\n",
      "\n",
      "Prompt: Write a short poem about technology and humanity.\n",
      "\n",
      "Temperature: 0.0\n",
      "------------------------------------------------------------\n",
      "# Digital Hearts\n",
      "\n",
      "We built machines to think like us,\n",
      "Then learned to think like them‚Äî\n",
      "Our hearts now beat in binary,\n",
      "Our souls sync at 8 AM.\n",
      "\n",
      "We touch through glass, we love through light,\n",
      "Connected, yet alone,\n",
      "The warmth of hands we used to hold\n",
      "Replaced by glowing phones.\n",
      "\n",
      "But still within the circuits' hum,\n",
      "A human truth remains:\n",
      "No algorithm yet can match\n",
      "The poetry in our veins.\n",
      "\n",
      "\n",
      "Temperature: 0.5\n",
      "------------------------------------------------------------\n",
      "# Digital Hearts\n",
      "\n",
      "We built machines to think like us,\n",
      "To calculate, connect, and see‚Äî\n",
      "Yet still we yearn for human touch,\n",
      "For warmth no code can ever be.\n",
      "\n",
      "Through glowing screens we reach across\n",
      "The distances that keep us far,\n",
      "But find that what we've gained and lost\n",
      "Are both contained in who we are.\n",
      "\n",
      "The tools we make reflect our mind:\n",
      "Both brilliant light and shadowed flaw‚Äî\n",
      "In silicon and steel we find\n",
      "Ourselves, the makers of it all.\n",
      "\n",
      "\n",
      "Temperature: 1.0\n",
      "------------------------------------------------------------\n",
      "# Connection\n",
      "\n",
      "We built bridges of light,\n",
      "spanning continents in milliseconds‚Äî\n",
      "yet struggle to cross the dinner table.\n",
      "\n",
      "Our phones remember everything;\n",
      "we forget to look up.\n",
      "\n",
      "A thousand friends glow in our palms\n",
      "while loneliness hums\n",
      "in the blue-lit dark.\n",
      "\n",
      "Still, a child laughs at a video call,\n",
      "grandparents wave from across the world,\n",
      "and love finds a way\n",
      "through fiber and code‚Äî\n",
      "\n",
      "reminding us:\n",
      "the technology changes,\n",
      "the heart remains.\n",
      "\n",
      "\n",
      "\n",
      "============================================================\n",
      "REFLECTION\n",
      "============================================================\n",
      "\n",
      "\n",
      "### Temperature 0.0 Analysis\n",
      "\n",
      "[What did you notice about consistency and predictability?]\n",
      "\n",
      "### Temperature 0.5 Analysis\n",
      "\n",
      "[What balance did you see between creativity and consistency?]\n",
      "\n",
      "### Temperature 1.0 Analysis\n",
      "\n",
      "[How creative/varied was this response?]\n",
      "\n",
      "### Conclusion\n",
      "\n",
      "**Best temperature for this task:** [0.0 / 0.5 / 1.0]\n",
      "\n",
      "**Reasoning:** [Explain your choice]\n",
      "\n",
      "### When to Use Each Temperature\n",
      "\n",
      "- **Temperature 0.0:** [Your use cases - e.g., factual Q&A, data extraction]\n",
      "- **Temperature 0.5:** [Your use cases - e.g., general explanations, summaries]\n",
      "- **Temperature 1.0:** [Your use cases - e.g., creative writing, brainstorming]\n",
      "\n",
      "\n",
      "üíæ Reflection appended to: homework_reflection.md\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO - Task 2: Temperature Exploration\n",
    "from src.utils import append_to_reflection\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"TASK 2: Temperature Exploration\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "\n",
    "# ============================================================================\n",
    "# TODO: Choose a creative prompt\n",
    "# ============================================================================\n",
    "\n",
    "creative_prompt = \"\"\"\n",
    "Write a short poem about technology and humanity.\n",
    "\"\"\"\n",
    "\n",
    "print(f\"Prompt: {creative_prompt.strip()}\")\n",
    "print()\n",
    "\n",
    "temperatures_to_test = [0.0, 0.5, 1.0]\n",
    "responses_by_temp = {}\n",
    "\n",
    "for temp in temperatures_to_test:\n",
    "    print(f\"Temperature: {temp}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    response = client.generate(\n",
    "        prompt=creative_prompt,\n",
    "        temperature=temp,\n",
    "        max_tokens=150\n",
    "    )\n",
    "    \n",
    "    if \"error\" not in response:\n",
    "        print(response['content'])\n",
    "        responses_by_temp[temp] = response['content']\n",
    "        tracker.add_call(response)\n",
    "    else:\n",
    "        print(f\"Error: {response['error']}\")\n",
    "        responses_by_temp[temp] = f\"Error: {response['error']}\"\n",
    "    \n",
    "    print()\n",
    "    print()\n",
    "    time.sleep(0.5)\n",
    "\n",
    "# ============================================================================\n",
    "# TODO: Document your observations\n",
    "# ============================================================================\n",
    "\n",
    "if responses_by_temp:\n",
    "    print()\n",
    "    print(\"=\" * 60)\n",
    "    print(\"REFLECTION\")\n",
    "    print(\"=\" * 60)\n",
    "    print()\n",
    "    \n",
    "    reflection = f\"\"\"\n",
    "### Temperature 0.0 Analysis\n",
    "\n",
    "[What did you notice about consistency and predictability?]\n",
    "\n",
    "### Temperature 0.5 Analysis\n",
    "\n",
    "[What balance did you see between creativity and consistency?]\n",
    "\n",
    "### Temperature 1.0 Analysis\n",
    "\n",
    "[How creative/varied was this response?]\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "**Best temperature for this task:** [0.0 / 0.5 / 1.0]\n",
    "\n",
    "**Reasoning:** [Explain your choice]\n",
    "\n",
    "### When to Use Each Temperature\n",
    "\n",
    "- **Temperature 0.0:** [Your use cases - e.g., factual Q&A, data extraction]\n",
    "- **Temperature 0.5:** [Your use cases - e.g., general explanations, summaries]\n",
    "- **Temperature 1.0:** [Your use cases - e.g., creative writing, brainstorming]\n",
    "\"\"\"\n",
    "    \n",
    "    print(reflection)\n",
    "    \n",
    "    # Save to consolidated reflection file\n",
    "    reflection_file = append_to_reflection(\n",
    "        notebook=\"02\",\n",
    "        section_title=\"Task 2 - Temperature Exploration\",\n",
    "        reflection_content=reflection,\n",
    "        output_dir=os.path.join(parent_dir, 'outputs')\n",
    "    )\n",
    "    \n",
    "    print()\n",
    "    print(f\"üíæ Reflection appended to: {os.path.basename(reflection_file)}\")\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf222c6c",
   "metadata": {},
   "source": [
    "### üìù Task 3: Cost Optimization Challenge\n",
    "\n",
    "Write the same request in two ways and compare token usage.\n",
    "\n",
    "**Goal:** Learn to write concise prompts without sacrificing clarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40cdd50e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TASK 3: Cost Optimization Challenge\n",
      "============================================================\n",
      "\n",
      "Testing VERBOSE version...\n",
      "------------------------------------------------------------\n",
      "I would really appreciate it if you could kindly provide me with a detailed \n",
      "and comprehensive explanation of how machine learning algorithms work, \n",
      "including all the important concepts and technical details that I should know \n",
      "about as a beginner who is just starting to learn about this fascinating field.\n",
      "\n",
      "‚úì Input tokens: 68\n",
      "‚úì Estimated cost: $0.003231\n",
      "\n",
      "\n",
      "Testing CONCISE version...\n",
      "------------------------------------------------------------\n",
      "Explain how machine learning algorithms work. Focus on key concepts for beginners.\n",
      "\n",
      "‚úì Input tokens: 25\n",
      "‚úì Estimated cost: $0.003063\n",
      "\n",
      "\n",
      "============================================================\n",
      "COMPARISON\n",
      "============================================================\n",
      "üìä Token savings: 43 tokens (63.2%)\n",
      "üí∞ Cost savings: $0.000168 per request\n",
      "üí∞ Over 100 requests: $0.0168\n",
      "\n",
      "============================================================\n",
      "REFLECTION\n",
      "============================================================\n",
      "\n",
      "\n",
      "### Comparison Results\n",
      "\n",
      "- **Token savings:** 43 tokens (63.2%)\n",
      "- **Cost savings per request:** $0.000168\n",
      "- **Projected savings (100 requests):** $0.0168\n",
      "\n",
      "### Quality Analysis\n",
      "\n",
      "**Did the verbose version produce a better response?**\n",
      "[Your analysis - was the extra wordiness worth it?]\n",
      "\n",
      "**Was the concise version still clear and complete?**\n",
      "[Your analysis - did you lose any important information?]\n",
      "\n",
      "### Key Lessons Learned\n",
      "\n",
      "1. [What did you learn about prompt efficiency?]\n",
      "2. [When might verbose prompts be justified?]\n",
      "3. [How will this change your prompting habits?]\n",
      "\n",
      "### My Cost Optimization Strategy\n",
      "\n",
      "Going forward, I will:\n",
      "- [Strategy 1]\n",
      "- [Strategy 2]\n",
      "- [Strategy 3]\n",
      "\n",
      "\n",
      "üíæ Reflection appended to: homework_reflection.md\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO - Task 3: Cost Optimization Challenge\n",
    "from src.utils import append_to_reflection\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"TASK 3: Cost Optimization Challenge\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "\n",
    "# ============================================================================\n",
    "# TODO: Write verbose and concise versions\n",
    "# ============================================================================\n",
    "\n",
    "verbose_prompt = \"\"\"\n",
    "I would really appreciate it if you could kindly provide me with a detailed \n",
    "and comprehensive explanation of how machine learning algorithms work, \n",
    "including all the important concepts and technical details that I should know \n",
    "about as a beginner who is just starting to learn about this fascinating field.\n",
    "\"\"\"\n",
    "\n",
    "concise_prompt = \"\"\"\n",
    "Explain how machine learning algorithms work. Focus on key concepts for beginners.\n",
    "\"\"\"\n",
    "\n",
    "# ============================================================================\n",
    "# Run comparison\n",
    "# ============================================================================\n",
    "\n",
    "print(\"Testing VERBOSE version...\")\n",
    "print(\"-\" * 60)\n",
    "print(verbose_prompt.strip())\n",
    "print()\n",
    "\n",
    "verbose_response = client.generate(\n",
    "    prompt=verbose_prompt,\n",
    "    temperature=0.7,\n",
    "    max_tokens=200\n",
    ")\n",
    "\n",
    "verbose_tokens = 0\n",
    "verbose_cost = 0\n",
    "\n",
    "if \"error\" not in verbose_response:\n",
    "    verbose_tokens = verbose_response['usage']['input_tokens']\n",
    "    verbose_cost = estimate_cost(verbose_prompt, verbose_response['usage']['output_tokens'], client.default_model)\n",
    "    \n",
    "    print(f\"‚úì Input tokens: {verbose_tokens}\")\n",
    "    print(f\"‚úì Estimated cost: ${verbose_cost:.6f}\")\n",
    "    print()\n",
    "    \n",
    "    tracker.add_call(verbose_response)\n",
    "\n",
    "print()\n",
    "print(\"Testing CONCISE version...\")\n",
    "print(\"-\" * 60)\n",
    "print(concise_prompt.strip())\n",
    "print()\n",
    "\n",
    "concise_response = client.generate(\n",
    "    prompt=concise_prompt,\n",
    "    temperature=0.7,\n",
    "    max_tokens=200\n",
    ")\n",
    "\n",
    "concise_tokens = 0\n",
    "concise_cost = 0\n",
    "\n",
    "if \"error\" not in concise_response:\n",
    "    concise_tokens = concise_response['usage']['input_tokens']\n",
    "    concise_cost = estimate_cost(concise_prompt, concise_response['usage']['output_tokens'], client.default_model)\n",
    "    \n",
    "    print(f\"‚úì Input tokens: {concise_tokens}\")\n",
    "    print(f\"‚úì Estimated cost: ${concise_cost:.6f}\")\n",
    "    print()\n",
    "    \n",
    "    tracker.add_call(concise_response)\n",
    "\n",
    "# Calculate savings\n",
    "if \"error\" not in verbose_response and \"error\" not in concise_response:\n",
    "    print()\n",
    "    print(\"=\" * 60)\n",
    "    print(\"COMPARISON\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    token_saved = verbose_tokens - concise_tokens\n",
    "    token_saved_pct = (token_saved / verbose_tokens * 100) if verbose_tokens > 0 else 0\n",
    "    cost_saved = verbose_cost - concise_cost\n",
    "    \n",
    "    print(f\"üìä Token savings: {token_saved} tokens ({token_saved_pct:.1f}%)\")\n",
    "    print(f\"üí∞ Cost savings: ${cost_saved:.6f} per request\")\n",
    "    print(f\"üí∞ Over 100 requests: ${cost_saved * 100:.4f}\")\n",
    "    print()\n",
    "    \n",
    "    # ========================================================================\n",
    "    # TODO: Add your reflections\n",
    "    # ========================================================================\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"REFLECTION\")\n",
    "    print(\"=\" * 60)\n",
    "    print()\n",
    "    \n",
    "    reflection = f\"\"\"\n",
    "### Comparison Results\n",
    "\n",
    "- **Token savings:** {token_saved} tokens ({token_saved_pct:.1f}%)\n",
    "- **Cost savings per request:** ${cost_saved:.6f}\n",
    "- **Projected savings (100 requests):** ${cost_saved * 100:.4f}\n",
    "\n",
    "### Quality Analysis\n",
    "\n",
    "**Did the verbose version produce a better response?**\n",
    "[Your analysis - was the extra wordiness worth it?]\n",
    "\n",
    "**Was the concise version still clear and complete?**\n",
    "[Your analysis - did you lose any important information?]\n",
    "\n",
    "### Key Lessons Learned\n",
    "\n",
    "1. [What did you learn about prompt efficiency?]\n",
    "2. [When might verbose prompts be justified?]\n",
    "3. [How will this change your prompting habits?]\n",
    "\n",
    "### My Cost Optimization Strategy\n",
    "\n",
    "Going forward, I will:\n",
    "- [Strategy 1]\n",
    "- [Strategy 2]\n",
    "- [Strategy 3]\n",
    "\"\"\"\n",
    "    \n",
    "    print(reflection)\n",
    "    \n",
    "    # Save to consolidated reflection file\n",
    "    reflection_file = append_to_reflection(\n",
    "        notebook=\"02\",\n",
    "        section_title=\"Task 3 - Cost Optimization\",\n",
    "        reflection_content=reflection,\n",
    "        output_dir=os.path.join(parent_dir, 'outputs')\n",
    "    )\n",
    "    \n",
    "    print()\n",
    "    print(f\"üíæ Reflection appended to: {os.path.basename(reflection_file)}\")\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d04043",
   "metadata": {},
   "source": [
    "---\n",
    "## üìä Section 2 Summary\n",
    "\n",
    "Let's review what you've learned and check your progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddf5e740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "SECTION 2: LEARNING CHECKPOINT\n",
      "============================================================\n",
      "\n",
      "‚úÖ Concepts Covered:\n",
      "\n",
      "  ‚úì System vs User prompts\n",
      "  ‚úì Temperature parameter (0.0-1.0)\n",
      "  ‚úì Max tokens (response length)\n",
      "  ‚úì Stop reasons (natural vs cut off)\n",
      "  ‚úì Token estimation\n",
      "  ‚úì Cost tracking and optimization\n",
      "  ‚úì System prompt patterns\n",
      "\n",
      "üéØ Skills Gained:\n",
      "\n",
      "  ‚úì Make basic API calls\n",
      "  ‚úì Control LLM behavior with system prompts\n",
      "  ‚úì Choose appropriate temperature settings\n",
      "  ‚úì Estimate and manage costs\n",
      "  ‚úì Write concise, effective prompts\n",
      "\n",
      "üìä Your API Usage This Notebook:\n",
      "\n",
      "============================================================\n",
      "üí∞ API COST REPORT\n",
      "============================================================\n",
      "Total API calls: 4\n",
      "Total input tokens: 155\n",
      "Total output tokens: 616\n",
      "Total cost: $0.0097\n",
      "\n",
      "Recent calls:\n",
      "  1. [01:11:56] sonnet - 101in/300out - $0.0048\n",
      "  2. [01:14:40] sonnet - 18in/104out - $0.0016\n",
      "  3. [01:14:45] sonnet - 18in/96out - $0.0015\n",
      "  4. [01:14:51] sonnet - 18in/116out - $0.0018\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Learning Checkpoint\n",
    "print(\"=\" * 60)\n",
    "print(\"SECTION 2: LEARNING CHECKPOINT\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "\n",
    "print(\"‚úÖ Concepts Covered:\")\n",
    "print()\n",
    "print(\"  ‚úì System vs User prompts\")\n",
    "print(\"  ‚úì Temperature parameter (0.0-1.0)\")\n",
    "print(\"  ‚úì Max tokens (response length)\")\n",
    "print(\"  ‚úì Stop reasons (natural vs cut off)\")\n",
    "print(\"  ‚úì Token estimation\")\n",
    "print(\"  ‚úì Cost tracking and optimization\")\n",
    "print(\"  ‚úì System prompt patterns\")\n",
    "print()\n",
    "\n",
    "print(\"üéØ Skills Gained:\")\n",
    "print()\n",
    "print(\"  ‚úì Make basic API calls\")\n",
    "print(\"  ‚úì Control LLM behavior with system prompts\")\n",
    "print(\"  ‚úì Choose appropriate temperature settings\")\n",
    "print(\"  ‚úì Estimate and manage costs\")\n",
    "print(\"  ‚úì Write concise, effective prompts\")\n",
    "print()\n",
    "\n",
    "# Show final cost report\n",
    "print(\"üìä Your API Usage This Notebook:\")\n",
    "print()\n",
    "tracker.report()\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95faada",
   "metadata": {},
   "source": [
    "## ü§î Reflection Questions\n",
    "\n",
    "Take a moment to reflect on what you learned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "498a3694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "OVERALL REFLECTION\n",
      "============================================================\n",
      "\n",
      "\n",
      "### 1. What surprised you most about system prompts?\n",
      "\n",
      "[Your answer]\n",
      "\n",
      "### 2. For factual questions, what temperature do you prefer and why?\n",
      "\n",
      "[Your answer]\n",
      "\n",
      "### 3. What's your main strategy for keeping API costs low?\n",
      "\n",
      "[Your answer]\n",
      "\n",
      "### 4. What's one practical use case where you'd use these techniques?\n",
      "\n",
      "[Your answer]\n",
      "\n",
      "### 5. What was your most interesting finding from this notebook?\n",
      "\n",
      "[Your answer]\n",
      "\n",
      "### 6. What will you do differently in future prompting?\n",
      "\n",
      "[Your answer]\n",
      "\n",
      "\n",
      "üíæ Reflection appended to: homework_reflection.md\n",
      "\n",
      "============================================================\n",
      "‚úÖ NOTEBOOK 02 COMPLETE\n",
      "============================================================\n",
      "\n",
      "All your reflections are saved in: outputs/homework_reflection.md\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Overall Notebook Reflection\n",
    "from src.utils import append_to_reflection\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"OVERALL REFLECTION\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "\n",
    "# ============================================================================\n",
    "# TODO: Answer these reflection questions\n",
    "# ============================================================================\n",
    "\n",
    "reflection = \"\"\"\n",
    "### 1. What surprised you most about system prompts?\n",
    "\n",
    "[Your answer]\n",
    "\n",
    "### 2. For factual questions, what temperature do you prefer and why?\n",
    "\n",
    "[Your answer]\n",
    "\n",
    "### 3. What's your main strategy for keeping API costs low?\n",
    "\n",
    "[Your answer]\n",
    "\n",
    "### 4. What's one practical use case where you'd use these techniques?\n",
    "\n",
    "[Your answer]\n",
    "\n",
    "### 5. What was your most interesting finding from this notebook?\n",
    "\n",
    "[Your answer]\n",
    "\n",
    "### 6. What will you do differently in future prompting?\n",
    "\n",
    "[Your answer]\n",
    "\"\"\"\n",
    "\n",
    "print(reflection)\n",
    "\n",
    "# Save to consolidated reflection file\n",
    "reflection_file = append_to_reflection(\n",
    "    notebook=\"02\",\n",
    "    section_title=\"Overall Reflection\",\n",
    "    reflection_content=reflection,\n",
    "    output_dir=os.path.join(parent_dir, 'outputs')\n",
    ")\n",
    "\n",
    "print()\n",
    "print(f\"üíæ Reflection appended to: {os.path.basename(reflection_file)}\")\n",
    "print()\n",
    "print(\"=\" * 60)\n",
    "print(\"‚úÖ NOTEBOOK 02 COMPLETE\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "print(f\"All your reflections are saved in: outputs/homework_reflection.md\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027a36a7",
   "metadata": {},
   "source": [
    "---\n",
    "## ‚úÖ Notebook 02 Complete!\n",
    "\n",
    "### üéâ Excellent Work!\n",
    "\n",
    "You've mastered the fundamentals of LLM interaction:\n",
    "- ‚úÖ System and user prompts\n",
    "- ‚úÖ Temperature control\n",
    "- ‚úÖ Token management\n",
    "- ‚úÖ Cost optimization\n",
    "- ‚úÖ Response analysis\n",
    "\n",
    "### üìà Progress Tracker\n",
    "```\n",
    "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 25% Complete\n",
    "\n",
    "‚úì Notebook 00: Setup Verification\n",
    "‚úì Notebook 01: Environment Setup\n",
    "‚úì Notebook 02: LLM Basics ‚Üê YOU ARE HERE\n",
    "‚óã Notebook 03: CO-STAR Framework\n",
    "‚óã Notebook 04: Structured Outputs\n",
    "‚óã Notebook 05: Chain of Thought\n",
    "‚óã Notebook 06: Model Comparison\n",
    "‚óã Notebook 07: MCP Introduction\n",
    "‚óã Notebook 08: Project Kickoff\n",
    "```\n",
    "\n",
    "### üéØ Key Takeaways\n",
    "\n",
    "1. **System prompts are powerful** - They're your main control mechanism\n",
    "2. **Temperature matters** - 0.0 for facts, 1.0 for creativity\n",
    "3. **Tokens = Money** - Be concise but clear\n",
    "4. **Track everything** - Know your costs!\n",
    "\n",
    "### üìö What's Next?\n",
    "\n",
    "**Notebook 03: CO-STAR Framework**\n",
    "- Learn structured prompt engineering\n",
    "- Master the 6 components of effective prompts\n",
    "- Build production-quality prompts\n",
    "- Create reusable prompt templates\n",
    "\n",
    "### üíæ Don't Forget!\n",
    "\n",
    "- Save this notebook\n",
    "- Review your reflection\n",
    "- Keep cost tracker data for final report\n",
    "\n",
    "---\n",
    "\n",
    "**Ready for advanced prompt engineering?** üöÄ\n",
    "\n",
    "**Next:** `notebooks/03_costar_framework.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e84163d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "SAVING PROGRESS\n",
      "============================================================\n",
      "\n",
      "‚úì Progress saved to outputs/progress.json\n",
      "\n",
      "Notebooks completed: 1/8\n",
      "Total API calls: 4\n",
      "Total cost so far: $0.0097\n",
      "\n",
      "üéâ Great job! See you in Notebook 03!\n"
     ]
    }
   ],
   "source": [
    "# Save Progress\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"SAVING PROGRESS\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "\n",
    "# Create progress report\n",
    "progress = {\n",
    "    \"notebook\": \"02_llm_basics\",\n",
    "    \"completed_at\": datetime.now().isoformat(),\n",
    "    \"path\": PATH,\n",
    "    \"model\": client.default_model,\n",
    "    \"api_calls\": len(tracker.calls),\n",
    "    \"total_cost\": tracker.total_cost,\n",
    "    \"total_tokens\": tracker.total_input_tokens + tracker.total_output_tokens,\n",
    "    \"tasks_completed\": {\n",
    "        \"task_1_custom_system_prompt\": True,  # Update based on your work\n",
    "        \"task_2_temperature_exploration\": True,\n",
    "        \"task_3_cost_optimization\": True\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save progress\n",
    "progress_file = os.path.join(parent_dir, 'outputs', 'progress.json')\n",
    "\n",
    "# Load existing progress if it exists\n",
    "if os.path.exists(progress_file):\n",
    "    with open(progress_file, 'r') as f:\n",
    "        all_progress = json.load(f)\n",
    "else:\n",
    "    all_progress = {}\n",
    "\n",
    "all_progress['notebook_02'] = progress\n",
    "\n",
    "with open(progress_file, 'w') as f:\n",
    "    json.dump(all_progress, f, indent=2)\n",
    "\n",
    "print(\"‚úì Progress saved to outputs/progress.json\")\n",
    "print()\n",
    "print(f\"Notebooks completed: {len([k for k in all_progress.keys() if k.startswith('notebook')])}/8\")\n",
    "print(f\"Total API calls: {progress['api_calls']}\")\n",
    "print(f\"Total cost so far: ${progress['total_cost']:.4f}\")\n",
    "print()\n",
    "print(\"üéâ Great job! See you in Notebook 03!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c764280b",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
