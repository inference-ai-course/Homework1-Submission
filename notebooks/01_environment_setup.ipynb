{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bf84c82",
   "metadata": {},
   "source": [
    "# ‚öôÔ∏è Notebook 01: Environment Setup\n",
    "\n",
    "**Time:** 20 minutes  \n",
    "**Goal:** Configure your environment and verify everything works\n",
    "\n",
    "This notebook will:\n",
    "1. Help you choose your path (Claude/Ollama/Hybrid)\n",
    "2. Save your configuration\n",
    "3. Test the pre-installed modules\n",
    "4. Make your first API call\n",
    "\n",
    "**Note:** The `src/` modules are already provided - you just need to configure them!\n",
    "\n",
    "Let's get started! üöÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926be9dd",
   "metadata": {},
   "source": [
    "### Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e93b783a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "NOTEBOOK 01: ENVIRONMENT SETUP\n",
      "============================================================\n",
      "\n",
      "Notebook directory: /Users/scott/Documents/inferenceAI/Homework1-Submission/notebooks\n",
      "Project root: /Users/scott/Documents/inferenceAI/Homework1-Submission\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add parent directory to path so we can import from src/\n",
    "notebook_dir = os.getcwd()\n",
    "parent_dir = str(Path(notebook_dir).parent)\n",
    "\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.insert(0, parent_dir)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"NOTEBOOK 01: ENVIRONMENT SETUP\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "print(f\"Notebook directory: {notebook_dir}\")\n",
    "print(f\"Project root: {parent_dir}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e458e1",
   "metadata": {},
   "source": [
    "### Test Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70e8ebcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TESTING MODULE IMPORTS\n",
      "============================================================\n",
      "\n",
      "‚úÖ All modules imported successfully!\n",
      "\n",
      "Available:\n",
      "  ‚úì LLMClient\n",
      "  ‚úì CostTracker\n",
      "  ‚úì Utility functions\n",
      "  ‚úì CO-STAR templates\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"TESTING MODULE IMPORTS\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "\n",
    "try:\n",
    "    from src.llm_client import LLMClient\n",
    "    from src.cost_tracker import CostTracker\n",
    "    from src.utils import estimate_tokens, estimate_cost, format_response\n",
    "    from src.prompt_templates import COSTARTemplate\n",
    "    \n",
    "    print(\"‚úÖ All modules imported successfully!\")\n",
    "    print()\n",
    "    print(\"Available:\")\n",
    "    print(\"  ‚úì LLMClient\")\n",
    "    print(\"  ‚úì CostTracker\")\n",
    "    print(\"  ‚úì Utility functions\")\n",
    "    print(\"  ‚úì CO-STAR templates\")\n",
    "    print()\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Import failed: {e}\")\n",
    "    print()\n",
    "    print(\"Troubleshooting:\")\n",
    "    print(\"  1. Make sure src/ directory exists\")\n",
    "    print(\"  2. Check all .py files are present\")\n",
    "    print(\"  3. Run Notebook 00 for diagnostics\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a438f4e4",
   "metadata": {},
   "source": [
    "## üìç Step 1: Choose Your Path\n",
    "\n",
    "Before we test the API, you need to decide which path you'll follow.\n",
    "\n",
    "### Path A: Claude API (Cloud) ‚òÅÔ∏è\n",
    "- **Best for:** Quality results, course alignment  \n",
    "- **Cost:** ~$1-2 for this assignment  \n",
    "- **Requirements:** API key, internet  \n",
    "\n",
    "### Path B: Ollama (Local) üè†\n",
    "- **Best for:** Zero cost, unlimited experiments  \n",
    "- **Cost:** $0 (free!)  \n",
    "- **Requirements:** 8GB+ RAM, Ollama installed  \n",
    "\n",
    "### Path C: Hybrid üîÑ\n",
    "- **Best for:** Most students  \n",
    "- **Strategy:** Use Ollama for learning, Claude for deliverables  \n",
    "- **Cost:** ~$0.50-1 for deliverables only  \n",
    "\n",
    "**Consider:**\n",
    "- Your budget\n",
    "- Your hardware capabilities\n",
    "- Your learning goals\n",
    "- Time constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a3acf9",
   "metadata": {},
   "source": [
    "### Path Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18d38d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "PATH SELECTION\n",
      "============================================================\n",
      "\n",
      "‚úì You selected: Path A\n",
      "\n",
      "üìå Claude API (Cloud)\n",
      "   Premium quality, costs money\n",
      "\n",
      "Requirements:\n",
      "  ‚Ä¢ Anthropic API key\n",
      "  ‚Ä¢ Internet connection\n",
      "\n",
      "Estimated cost: $1-2 for homework\n",
      "\n",
      "Available models:\n",
      "  ‚Ä¢ claude-sonnet-4-5-20250929\n",
      "  ‚Ä¢ claude-opus-4-5-20251101\n",
      "  ‚Ä¢ claude-haiku-4-5-20251001\n",
      "\n",
      "‚úì Configuration saved to src/config.py\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"PATH SELECTION\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "\n",
    "# ============================================================================\n",
    "# TODO: CHANGE THIS TO YOUR CHOSEN PATH\n",
    "# ============================================================================\n",
    "PATH = \"A\"  # Options: \"A\", \"B\", or \"C\"\n",
    "# ============================================================================\n",
    "\n",
    "if PATH not in [\"A\", \"B\", \"C\"]:\n",
    "    raise ValueError(\"PATH must be 'A', 'B', or 'C'\")\n",
    "\n",
    "path_info = {\n",
    "    \"A\": {\n",
    "        \"name\": \"Claude API (Cloud)\",\n",
    "        \"description\": \"Premium quality, costs money\",\n",
    "        \"requirements\": [\"Anthropic API key\", \"Internet connection\"],\n",
    "        \"estimated_cost\": \"$1-2 for homework\",\n",
    "        \"models\": [\"claude-sonnet-4-5-20250929\", \"claude-opus-4-5-20251101\", \"claude-haiku-4-5-20251001\"]\n",
    "    },\n",
    "    \"B\": {\n",
    "        \"name\": \"Ollama (Local)\",\n",
    "        \"description\": \"Free, unlimited experiments\",\n",
    "        \"requirements\": [\"8GB+ RAM\", \"Ollama installed\", \"Model downloaded\"],\n",
    "        \"estimated_cost\": \"$0 (free!)\",\n",
    "        \"models\": [\"llama3.2:3b\", \"llama3.1:8b\", \"mistral:7b\", \"qwen2.5:7b\"]\n",
    "    },\n",
    "    \"C\": {\n",
    "        \"name\": \"Hybrid\",\n",
    "        \"description\": \"Best of both worlds\",\n",
    "        \"requirements\": [\"Both A and B requirements\"],\n",
    "        \"estimated_cost\": \"$0.50-1 (Claude for deliverables only)\",\n",
    "        \"models\": [\"All models from A and B\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "info = path_info[PATH]\n",
    "\n",
    "print(f\"‚úì You selected: Path {PATH}\")\n",
    "print()\n",
    "print(f\"üìå {info['name']}\")\n",
    "print(f\"   {info['description']}\")\n",
    "print()\n",
    "print(\"Requirements:\")\n",
    "for req in info['requirements']:\n",
    "    print(f\"  ‚Ä¢ {req}\")\n",
    "print()\n",
    "print(f\"Estimated cost: {info['estimated_cost']}\")\n",
    "print()\n",
    "print(\"Available models:\")\n",
    "for model in info['models']:\n",
    "    print(f\"  ‚Ä¢ {model}\")\n",
    "print()\n",
    "\n",
    "# Save configuration\n",
    "config_file = os.path.join(src_dir, 'config.py')\n",
    "with open(config_file, 'w') as f:\n",
    "    f.write('\"\"\"Configuration for Week 1 notebooks\"\"\"\\n\\n')\n",
    "    f.write(f'# Your selected path\\n')\n",
    "    f.write(f'PATH = \"{PATH}\"\\n')\n",
    "\n",
    "print(f\"‚úì Configuration saved to src/config.py\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333581ba",
   "metadata": {},
   "source": [
    "## üìù Reflection: Why This Path?\n",
    "\n",
    "Take a moment to document your reasoning. This will be useful when writing your final resource analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e36b28b",
   "metadata": {},
   "source": [
    "### Document Your Path Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8e6aaa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "PATH SELECTION RATIONALE\n",
      "============================================================\n",
      "\n",
      "\n",
      "WHY I CHOSE PATH A: Claude API (Cloud)\n",
      "\n",
      "[Replace this with your reasoning. Consider:]\n",
      "\n",
      "Budget: \n",
      "[Your budget considerations]\n",
      "\n",
      "Hardware: \n",
      "[Your hardware situation]\n",
      "\n",
      "Learning Goals: \n",
      "[What do you want to learn?]\n",
      "\n",
      "Time Constraints: \n",
      "[How much time do you have?]\n",
      "\n",
      "Other Factors:\n",
      "[Anything else that influenced your decision]\n",
      "\n",
      "\n",
      "‚úì Saved to outputs/path_selection.md\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"PATH SELECTION RATIONALE\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "\n",
    "# TODO: Fill in your reasoning below\n",
    "rationale = \"\"\"\n",
    "WHY I CHOSE PATH {}: {}\n",
    "\n",
    "[Replace this with your reasoning. Consider:]\n",
    "\n",
    "Budget: \n",
    "[Your budget considerations]\n",
    "\n",
    "Hardware: \n",
    "[Your hardware situation]\n",
    "\n",
    "Learning Goals: \n",
    "[What do you want to learn?]\n",
    "\n",
    "Time Constraints: \n",
    "[How much time do you have?]\n",
    "\n",
    "Other Factors:\n",
    "[Anything else that influenced your decision]\n",
    "\"\"\".format(PATH, path_info[PATH]['name'])\n",
    "\n",
    "print(rationale)\n",
    "\n",
    "# Save to outputs\n",
    "outputs_dir = os.path.join(parent_dir, 'outputs')\n",
    "os.makedirs(outputs_dir, exist_ok=True)\n",
    "\n",
    "with open(os.path.join(outputs_dir, 'path_selection.md'), 'w') as f:\n",
    "    f.write(f\"# Path Selection: Path {PATH}\\n\\n\")\n",
    "    f.write(f\"**Selected:** {path_info[PATH]['name']}\\n\\n\")\n",
    "    f.write(rationale)\n",
    "\n",
    "print()\n",
    "print(\"‚úì Saved to outputs/path_selection.md\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda238da",
   "metadata": {},
   "source": [
    "## üîß Step 2: Initialize LLMClient\n",
    "\n",
    "Now let's initialize the LLM client with your chosen path.\n",
    "\n",
    "This will:\n",
    "- Load your API key (if Path A or C)\n",
    "- Connect to Ollama (if Path B or C)\n",
    "- Set default model\n",
    "- Verify everything works"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4e6ce3",
   "metadata": {},
   "source": [
    "### Load Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d967e579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "LOADING ENVIRONMENT\n",
      "============================================================\n",
      "\n",
      "‚úì Loaded environment from: /Users/scott/Documents/inferenceAI/Homework1-Submission/.env\n",
      "\n",
      "‚úì ANTHROPIC_API_KEY found (108 characters)\n",
      "  Starts with: sk-ant-...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"LOADING ENVIRONMENT\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "\n",
    "# Load .env file from parent directory\n",
    "env_path = os.path.join(parent_dir, '.env')\n",
    "\n",
    "if os.path.exists(env_path):\n",
    "    load_dotenv(env_path)\n",
    "    print(f\"‚úì Loaded environment from: {env_path}\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è  No .env file found at: {env_path}\")\n",
    "    if PATH in [\"A\", \"C\"]:\n",
    "        print(\"   This is required for Claude API!\")\n",
    "        print(\"   Create .env from .env.example and add your API key\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Check API key\n",
    "if PATH in [\"A\", \"C\"]:\n",
    "    api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "    if api_key:\n",
    "        print(f\"‚úì ANTHROPIC_API_KEY found ({len(api_key)} characters)\")\n",
    "        print(f\"  Starts with: {api_key[:7]}...\")\n",
    "    else:\n",
    "        print(\"‚ùå ANTHROPIC_API_KEY not found\")\n",
    "        print(\"   Required for Claude API (Path A or C)\")\n",
    "        print()\n",
    "        print(\"   Setup:\")\n",
    "        print(\"   1. Copy .env.example to .env\")\n",
    "        print(\"   2. Add: ANTHROPIC_API_KEY=your_key_here\")\n",
    "        print(\"   3. Get key from: console.anthropic.com\")\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af46697",
   "metadata": {},
   "source": [
    "### Initialize LLMClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0dd75e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "INITIALIZING LLMClient\n",
      "============================================================\n",
      "\n",
      "Initializing LLMClient with Path A...\n",
      "\n",
      "‚úì Claude API client initialized\n",
      "  Default model: claude-sonnet-4-5-20250929\n",
      "  Available: Opus 4.5, Sonnet 4.5, Haiku 4.5\n",
      "\n",
      "============================================================\n",
      "‚úÖ LLMClient initialized successfully!\n",
      "============================================================\n",
      "\n",
      "Default model: claude-sonnet-4-5-20250929\n",
      "Path: A\n",
      "\n",
      "Available models (3):\n",
      "  ‚Ä¢ claude-sonnet-4-5-20250929\n",
      "  ‚Ä¢ claude-opus-4-5-20251101\n",
      "  ‚Ä¢ claude-haiku-4-5-20251001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from src.llm_client import LLMClient\n",
    "from src.config import PATH as SAVED_PATH\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"INITIALIZING LLMClient\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "\n",
    "# Verify saved path matches\n",
    "if PATH != SAVED_PATH:\n",
    "    print(f\"‚ö†Ô∏è  Warning: PATH mismatch!\")\n",
    "    print(f\"   You selected: {PATH}\")\n",
    "    print(f\"   Config file has: {SAVED_PATH}\")\n",
    "    print()\n",
    "    print(\"   Re-running cell 4 to update config...\")\n",
    "    # Update config\n",
    "    with open(os.path.join(src_dir, 'config.py'), 'w') as f:\n",
    "        f.write('\"\"\"Configuration for Week 1 notebooks\"\"\"\\n\\n')\n",
    "        f.write(f'PATH = \"{PATH}\"\\n')\n",
    "    print(\"   ‚úì Config updated\")\n",
    "    print()\n",
    "\n",
    "print(f\"Initializing LLMClient with Path {PATH}...\")\n",
    "print()\n",
    "\n",
    "try:\n",
    "    client = LLMClient(path=PATH)\n",
    "    \n",
    "    print()\n",
    "    print(\"=\" * 60)\n",
    "    print(\"‚úÖ LLMClient initialized successfully!\")\n",
    "    print(\"=\" * 60)\n",
    "    print()\n",
    "    print(f\"Default model: {client.default_model}\")\n",
    "    print(f\"Path: {client.path}\")\n",
    "    print()\n",
    "    \n",
    "    # Show available models\n",
    "    available = client.get_available_models()\n",
    "    if available:\n",
    "        print(f\"Available models ({len(available)}):\")\n",
    "        for model in available:\n",
    "            print(f\"  ‚Ä¢ {model}\")\n",
    "    \n",
    "    print()\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Initialization failed!\")\n",
    "    print(f\"Error: {e}\")\n",
    "    print()\n",
    "    print(\"Troubleshooting:\")\n",
    "    \n",
    "    if PATH in [\"A\", \"C\"]:\n",
    "        print()\n",
    "        print(\"For Claude API:\")\n",
    "        print(\"  1. Check .env file exists and has ANTHROPIC_API_KEY\")\n",
    "        print(\"  2. Verify key is valid at console.anthropic.com\")\n",
    "        print(\"  3. Check internet connection\")\n",
    "    \n",
    "    if PATH in [\"B\", \"C\"]:\n",
    "        print()\n",
    "        print(\"For Ollama:\")\n",
    "        print(\"  1. Check Ollama is running: ollama serve\")\n",
    "        print(\"  2. Verify models installed: ollama list\")\n",
    "        print(\"  3. Pull a model: ollama pull llama3.2:3b\")\n",
    "    \n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8cfdd6e",
   "metadata": {},
   "source": [
    "## üß™ Step 3: Make Your First API Call\n",
    "\n",
    "Time to test everything with a simple API call!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf7075cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "FIRST API CALL TEST\n",
      "============================================================\n",
      "\n",
      "Prompt: Say 'Hello from Notebook 01! Setup successful!' and nothing else.\n",
      "\n",
      "Sending request...\n",
      "\n",
      "‚úÖ API call successful!\n",
      "============================================================\n",
      "\n",
      "üìä Metadata:\n",
      "  Model: claude-sonnet-4-5-20250929\n",
      "  Response time: 1.74 seconds\n",
      "  Input tokens: 24\n",
      "  Output tokens: 13\n",
      "  Stop reason: end_turn\n",
      "\n",
      "üí¨ Response:\n",
      "  --------------------------------------------------------\n",
      "  Hello from Notebook 01! Setup successful!\n",
      "  --------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"FIRST API CALL TEST\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "\n",
    "test_prompt = \"Say 'Hello from Notebook 01! Setup successful!' and nothing else.\"\n",
    "\n",
    "print(f\"Prompt: {test_prompt}\")\n",
    "print()\n",
    "print(\"Sending request...\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "response = client.generate(\n",
    "    prompt=test_prompt,\n",
    "    temperature=0.0,  # Deterministic for testing\n",
    "    max_tokens=50\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed = end_time - start_time\n",
    "\n",
    "print()\n",
    "\n",
    "if \"error\" in response:\n",
    "    print(\"‚ùå API call failed!\")\n",
    "    print()\n",
    "    print(f\"Error: {response['error']}\")\n",
    "    print()\n",
    "    print(\"Common issues:\")\n",
    "    print(\"  ‚Ä¢ Invalid API key\")\n",
    "    print(\"  ‚Ä¢ Ollama not running\")\n",
    "    print(\"  ‚Ä¢ Network connection problem\")\n",
    "    print(\"  ‚Ä¢ Rate limit exceeded\")\n",
    "    print()\n",
    "    print(\"Try running Notebook 00 for detailed diagnostics\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚úÖ API call successful!\")\n",
    "    print(\"=\" * 60)\n",
    "    print()\n",
    "    print(f\"üìä Metadata:\")\n",
    "    print(f\"  Model: {response['model']}\")\n",
    "    print(f\"  Response time: {elapsed:.2f} seconds\")\n",
    "    print(f\"  Input tokens: {response['usage']['input_tokens']}\")\n",
    "    print(f\"  Output tokens: {response['usage']['output_tokens']}\")\n",
    "    print(f\"  Stop reason: {response['stop_reason']}\")\n",
    "    print()\n",
    "    print(f\"üí¨ Response:\")\n",
    "    print(\"  \" + \"-\" * 56)\n",
    "    print(\"  \" + response['content'])\n",
    "    print(\"  \" + \"-\" * 56)\n",
    "    print()\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda0f153",
   "metadata": {},
   "source": [
    "## üí∞ Step 4: Initialize Cost Tracker\n",
    "\n",
    "Let's set up cost tracking so you can monitor your API usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9c9cc20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "COST TRACKING\n",
      "============================================================\n",
      "\n",
      "‚úì CostTracker initialized\n",
      "\n",
      "‚úì Added test call to tracker\n",
      "\n",
      "============================================================\n",
      "üí∞ API COST REPORT\n",
      "============================================================\n",
      "Total API calls: 1\n",
      "Total input tokens: 24\n",
      "Total output tokens: 13\n",
      "Total cost: $0.0003\n",
      "\n",
      "Recent calls:\n",
      "  1. [00:37:17] sonnet - 24in/13out - $0.0003\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from src.cost_tracker import CostTracker\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"COST TRACKING\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "\n",
    "# Initialize tracker\n",
    "tracker = CostTracker()\n",
    "\n",
    "print(\"‚úì CostTracker initialized\")\n",
    "print()\n",
    "\n",
    "# Add the test call (if it succeeded)\n",
    "if \"error\" not in response:\n",
    "    tracker.add_call(response)\n",
    "    print(\"‚úì Added test call to tracker\")\n",
    "    print()\n",
    "    \n",
    "    # Show report\n",
    "    tracker.report()\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No successful call to track yet\")\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33afcbe",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Step 5: Test Utility Functions\n",
    "\n",
    "Let's verify the utility functions work correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dbcaf64b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "UTILITY FUNCTIONS TEST\n",
      "============================================================\n",
      "\n",
      "Sample text: \"This is a sample prompt to test token estimation functionality.\"\n",
      "Character count: 63\n",
      "Estimated tokens: 15\n",
      "Rule: ~1 token per 4 characters\n",
      "\n",
      "Cost estimate for this prompt:\n",
      "  Input: ~15 tokens\n",
      "  Output: 200 tokens (estimated)\n",
      "  Model: claude-sonnet-4-5-20250929\n",
      "  Total cost: $0.003045\n",
      "\n",
      "Testing format_response()...\n",
      "\n",
      "Verbose format:\n",
      "============================================================\n",
      "Model: claude-sonnet-4-5-20250929\n",
      "Tokens: 24 in, 13 out\n",
      "Stop reason: end_turn\n",
      "============================================================\n",
      "Hello from Notebook 01! Setup successful!\n",
      "============================================================\n",
      "\n",
      "Concise format:\n",
      "Hello from Notebook 01! Setup successful!\n",
      "\n",
      "‚úÖ All utility functions working!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from src.utils import estimate_tokens, estimate_cost, format_response\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"UTILITY FUNCTIONS TEST\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "\n",
    "# Test token estimation\n",
    "test_text = \"This is a sample prompt to test token estimation functionality.\"\n",
    "estimated = estimate_tokens(test_text)\n",
    "\n",
    "print(f\"Sample text: \\\"{test_text}\\\"\")\n",
    "print(f\"Character count: {len(test_text)}\")\n",
    "print(f\"Estimated tokens: {estimated}\")\n",
    "print(f\"Rule: ~1 token per 4 characters\")\n",
    "print()\n",
    "\n",
    "# Test cost estimation\n",
    "estimated_cost_value = estimate_cost(test_text, output_tokens=200, model=client.default_model)\n",
    "\n",
    "print(f\"Cost estimate for this prompt:\")\n",
    "print(f\"  Input: ~{estimated} tokens\")\n",
    "print(f\"  Output: 200 tokens (estimated)\")\n",
    "print(f\"  Model: {client.default_model}\")\n",
    "print(f\"  Total cost: ${estimated_cost_value:.6f}\")\n",
    "print()\n",
    "\n",
    "# Test format_response\n",
    "if \"error\" not in response:\n",
    "    print(\"Testing format_response()...\")\n",
    "    print()\n",
    "    \n",
    "    # Verbose format\n",
    "    print(\"Verbose format:\")\n",
    "    print(format_response(response, verbose=True))\n",
    "    print()\n",
    "    \n",
    "    # Concise format\n",
    "    print(\"Concise format:\")\n",
    "    print(format_response(response, verbose=False))\n",
    "\n",
    "print()\n",
    "print(\"‚úÖ All utility functions working!\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5506746",
   "metadata": {},
   "source": [
    "## üé® Step 6: Preview CO-STAR Templates\n",
    "\n",
    "Let's look at the prompt templates we'll use in Notebook 03."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fad0d31e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CO-STAR TEMPLATE PREVIEW\n",
      "============================================================\n",
      "\n",
      "Example CO-STAR Prompt:\n",
      "============================================================\n",
      "# Context\n",
      "You are helping a student learn about machine learning.\n",
      "\n",
      "# Objective\n",
      "Explain what a neural network is in simple terms.\n",
      "\n",
      "# Style\n",
      "educational and clear\n",
      "\n",
      "# Tone\n",
      "friendly and encouraging\n",
      "\n",
      "# Audience\n",
      "beginner with no ML background\n",
      "\n",
      "# Response Format\n",
      "2-3 short paragraphs\n",
      "\n",
      "============================================================\n",
      "\n",
      "üí° We'll learn more about CO-STAR in Notebook 03!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from src.prompt_templates import COSTARTemplate\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"CO-STAR TEMPLATE PREVIEW\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "\n",
    "# Create a sample CO-STAR prompt\n",
    "sample_prompt = COSTARTemplate.build(\n",
    "    context=\"You are helping a student learn about machine learning.\",\n",
    "    objective=\"Explain what a neural network is in simple terms.\",\n",
    "    style=\"educational and clear\",\n",
    "    tone=\"friendly and encouraging\",\n",
    "    audience=\"beginner with no ML background\",\n",
    "    response_format=\"2-3 short paragraphs\"\n",
    ")\n",
    "\n",
    "print(\"Example CO-STAR Prompt:\")\n",
    "print(\"=\" * 60)\n",
    "print(sample_prompt)\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "\n",
    "print(\"üí° We'll learn more about CO-STAR in Notebook 03!\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5b33b3",
   "metadata": {},
   "source": [
    "## ‚úÖ Environment Setup Complete!\n",
    "\n",
    "### üéâ Congratulations!\n",
    "\n",
    "You've successfully:\n",
    "1. ‚úÖ Chosen your deployment path\n",
    "2. ‚úÖ Verified all modules are installed\n",
    "3. ‚úÖ Initialized LLMClient\n",
    "4. ‚úÖ Made your first successful API call\n",
    "5. ‚úÖ Set up cost tracking\n",
    "6. ‚úÖ Tested utility functions\n",
    "7. ‚úÖ Previewed CO-STAR templates\n",
    "\n",
    "### üìä Your Configuration\n",
    "\n",
    "- **Path:** {PATH}\n",
    "- **Model:** {client.default_model}\n",
    "- **API Test:** Successful\n",
    "- **Cost Tracker:** Active\n",
    "\n",
    "### üìÅ Files Created\n",
    "```\n",
    "outputs/\n",
    "‚îî‚îÄ‚îÄ path_selection.md        # Your path rationale\n",
    "\n",
    "src/\n",
    "‚îî‚îÄ‚îÄ config.py               # Your path configuration (updated)\n",
    "```\n",
    "\n",
    "### üéØ Next Steps\n",
    "\n",
    "You're all set up! The remaining notebooks will import from `src/` automatically.\n",
    "\n",
    "**Next:** Open `notebooks/02_llm_basics.ipynb`\n",
    "\n",
    "### üí° Tips for Success\n",
    "\n",
    "- Keep cost tracker running across all notebooks\n",
    "- Use `tracker.report()` to check spending\n",
    "- If switching paths, update PATH in cell 4 and rerun\n",
    "- Save your work frequently\n",
    "\n",
    "---\n",
    "\n",
    "**Ready for the next notebook!** üöÄ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "13a89f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "SETUP COMPLETE - SUMMARY\n",
      "============================================================\n",
      "\n",
      "\n",
      "‚úÖ Environment Setup Complete!\n",
      "\n",
      "Configuration:\n",
      "  Path: A (Claude API (Cloud))\n",
      "  Default Model: claude-sonnet-4-5-20250929\n",
      "\n",
      "Status:\n",
      "  ‚úì All modules imported\n",
      "  ‚úì LLMClient initialized\n",
      "  ‚úì First API call successful\n",
      "  ‚úì Cost tracking active\n",
      "\n",
      "Next Steps:\n",
      "  ‚Üí Open notebooks/02_llm_basics.ipynb\n",
      "  ‚Üí Continue learning!\n",
      "\n",
      "Files:\n",
      "  ‚Ä¢ outputs/path_selection.md (your rationale)\n",
      "  ‚Ä¢ src/config.py (path configuration)\n",
      "\n",
      "Summary saved to outputs/setup_summary.txt\n",
      "\n",
      "üéâ You're ready for Notebook 02!\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"SETUP COMPLETE - SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "\n",
    "summary = f\"\"\"\n",
    "‚úÖ Environment Setup Complete!\n",
    "\n",
    "Configuration:\n",
    "  Path: {PATH} ({path_info[PATH]['name']})\n",
    "  Default Model: {client.default_model}\n",
    "  \n",
    "Status:\n",
    "  ‚úì All modules imported\n",
    "  ‚úì LLMClient initialized\n",
    "  ‚úì First API call successful\n",
    "  ‚úì Cost tracking active\n",
    "  \n",
    "Next Steps:\n",
    "  ‚Üí Open notebooks/02_llm_basics.ipynb\n",
    "  ‚Üí Continue learning!\n",
    "\n",
    "Files:\n",
    "  ‚Ä¢ outputs/path_selection.md (your rationale)\n",
    "  ‚Ä¢ src/config.py (path configuration)\n",
    "\"\"\"\n",
    "\n",
    "print(summary)\n",
    "\n",
    "# Save summary\n",
    "with open(os.path.join(parent_dir, 'outputs', 'setup_summary.txt'), 'w') as f:\n",
    "    f.write(summary)\n",
    "    f.write(f\"\\nSetup completed: {time.strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "\n",
    "print(\"Summary saved to outputs/setup_summary.txt\")\n",
    "print()\n",
    "print(\"üéâ You're ready for Notebook 02!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
