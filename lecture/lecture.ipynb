{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Engineer in the\u000bGenerative AI Era \n",
    "## lecture 1 - Prompt Engineering with Jupyter Notebook \n",
    "### Introduction\n",
    "This notebook introduces prompt engineering techniques to effectively interact with large language models (LLMs). You'll learn how to craft prompts for various tasks, including summarization, inference, transformation, and expansion\n",
    "\n",
    "### 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\projects\\github\\mle_in_gen_ai-course\\.ws-venv\\lib\\site-packages (1.101.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\projects\\github\\mle_in_gen_ai-course\\.ws-venv\\lib\\site-packages (from openai) (4.10.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\projects\\github\\mle_in_gen_ai-course\\.ws-venv\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\projects\\github\\mle_in_gen_ai-course\\.ws-venv\\lib\\site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\projects\\github\\mle_in_gen_ai-course\\.ws-venv\\lib\\site-packages (from openai) (0.10.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\projects\\github\\mle_in_gen_ai-course\\.ws-venv\\lib\\site-packages (from openai) (2.11.7)\n",
      "Requirement already satisfied: sniffio in c:\\projects\\github\\mle_in_gen_ai-course\\.ws-venv\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\projects\\github\\mle_in_gen_ai-course\\.ws-venv\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\projects\\github\\mle_in_gen_ai-course\\.ws-venv\\lib\\site-packages (from openai) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\projects\\github\\mle_in_gen_ai-course\\.ws-venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\projects\\github\\mle_in_gen_ai-course\\.ws-venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\projects\\github\\mle_in_gen_ai-course\\.ws-venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\projects\\github\\mle_in_gen_ai-course\\.ws-venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\projects\\github\\mle_in_gen_ai-course\\.ws-venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\projects\\github\\mle_in_gen_ai-course\\.ws-venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\projects\\github\\mle_in_gen_ai-course\\.ws-venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
      "Requirement already satisfied: colorama in c:\\projects\\github\\mle_in_gen_ai-course\\.ws-venv\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the necessary libraries and set your OpenAI API key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "# client = openai.OpenAI(api_key='your-api-key-here')\n",
    "client = openai.OpenAI(\n",
    "    base_url = 'http://localhost:11434/v1',\n",
    "    api_key = 'ollama', # required, but unused\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Basic Prompting\n",
    "Let's start with a simple prompt to generate a response from the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is Paris.\n"
     ]
    }
   ],
   "source": [
    "def get_completion(prompt, model=\"llama3\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Example usage\n",
    "prompt = \"What is the capital of France?\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of Germany is Berlin.\n"
     ]
    }
   ],
   "source": [
    "# Exercise 1: Modify the prompt to ask about the capital of Germany.\n",
    "prompt = \"What is the capital of Germany?\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Summarization\n",
    "You can use prompts to summarize text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a summary of the text:\n",
      "\n",
      "Artificial intelligence (AI) is the ability of machines to mimic human intelligence by thinking and learning. AI has many practical uses across industries such as healthcare, finance, and transportation.\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "Artificial intelligence (AI) refers to the simulation of human intelligence in machines that are programmed to think and learn. It has applications in various fields, including healthcare, finance, and transportation.\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"Summarize the following text:\\n{text}\"\n",
    "response = get_completion(prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text argues that resilience is not just about recovering from adversity, but also about transforming and growing as a result of those challenges. It suggests that each setback or difficulty can serve as a teacher, helping us to reinvent ourselves and emerge stronger and wiser. Those who are resilient do not remain untouched by hardship, but rather are shaped by it, developing deeper empathy, sharper purpose, and a wider perspective. The text concludes that true resilience is quiet, steady, and often invisible until its effects become apparent, speaking to the strength that comes from choosing to rise above adversity.\n"
     ]
    }
   ],
   "source": [
    "# Exercise 2: Try summarizing a longer article or passage of your choice.\n",
    "text = \"\"\"\n",
    "    In the face of adversity, resilience isn't just about bouncing back—it's about transforming. \n",
    "    Like roots pushing through stone, growth often happens in resistance. Each challenge becomes a teacher; \n",
    "    each setback, a foundation for reinvention. Whether it's in personal loss, career disruption, or even global turmoil, \n",
    "    those who rise aren't untouched by hardship—they are shaped by it. They emerge with deeper empathy, sharper purpose, \n",
    "    and wider perspective. True resilience is quiet, steady, and often invisible until the bloom appears. And when it does, \n",
    "    it speaks of strength not just endured—but chosen.\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"Summarize the following text:\\n{text}\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Information Extraction\n",
    "Extract specific information from a given text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the extracted information:\n",
      "\n",
      "* Name: John Doe\n",
      "* Occupation: Research Scientist (specifically in software engineering)\n",
      "Here are the extracted information:\n",
      "\n",
      "* Name: John Doe\n",
      "* Occupation: Software Engineer (currently) and Research Scientist (at OpenAI)\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "John Doe, a 29-year-old software engineer from San Francisco, recently joined OpenAI as a research scientist.\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"Extract the name and occupation from the following text:\\n{text}\"\n",
    "response = get_completion(prompt)\n",
    "print(response)\n",
    "text = \"\"\"\n",
    "John Doe, a 29-year-old software engineer from San Francisco, recently joined OpenAI as a research scientist.\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"Extract the name and occupation from the following text:\\n{text}\"\n",
    "response = get_completion(prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the extracted information:\n",
      "\n",
      "* Age: 29\n",
      "* Location: San Francisco\n",
      "Here are the extracted information:\n",
      "\n",
      "* Age: 29\n",
      "* Location: San Francisco\n"
     ]
    }
   ],
   "source": [
    "# Exercise 3: Extract the age and location from the same text.\n",
    "text = \"\"\"\n",
    "John Doe, a 29-year-old software engineer from San Francisco, recently joined OpenAI as a research scientist.\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"Extract the age and location from the following text:\\n{text}\"\n",
    "response = get_completion(prompt)\n",
    "print(response)\n",
    "text = \"\"\"\n",
    "John Doe, a 29-year-old software engineer from San Francisco, recently joined OpenAI as a research scientist.\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"Extract the age and location from the following text:\\n{text}\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Transformation\n",
    "Transform text from one format or style to another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le temps est agréable aujourd'hui.\n",
      "\n",
      "(Note: \"nice\" can also be translated as \"agréable\", but if you want to use a more formal tone, you could say \"le ciel est ensoleillé aujourd'hui\" which means \"the sky is sunny today\".)\n"
     ]
    }
   ],
   "source": [
    "text = \"The weather is nice today.\"\n",
    "\n",
    "prompt = f\"Translate the following text to French:\\n{text}\"\n",
    "response = get_completion(prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El tiempo está lloviendo hoy.\n",
      "\n",
      "(Note: \"raining\" can also be translated as \"lluvia\" in this context, but I used the verb \"está lloviendo\" to convey the idea that it's currently raining.)\n"
     ]
    }
   ],
   "source": [
    "# Exercise 4: Translate a different sentence to Spanish.\n",
    "text = \"The weather is raining today.\"\n",
    "\n",
    "prompt = f\"Translate the following text to Spanish:\\n{text}\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Expansion\n",
    "Expand a short prompt into a more detailed response.​\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the heart of the mystical forest, a young dragon named Ember had always been fascinated by the humans and their strange, glowing rectangles. She would often sneak peeks at them as they worked on their \"computers,\" mesmerized by the way their fingers danced across the screens.\n",
      "\n",
      "One day, while exploring a hidden glade, Ember stumbled upon an old laptop left behind by a careless camper. The device was dusty and outdated, but to Ember's eyes, it sparkled like treasure. She carefully picked it up, feeling the weight of the machine in her claws.\n",
      "\n",
      "As she examined the laptop, Ember noticed strange symbols and patterns on the screen. She had seen similar markings on ancient scrolls hidden deep within the forest's ruins. Intrigued, she decided to investigate further.\n",
      "\n",
      "Ember spent hours studying the laptop's keyboard, marveling at the way the keys clicked beneath her claws. She began to experiment with typing, starting with simple phrases and gradually moving on to more complex sequences of code.\n",
      "\n",
      "At first, the humans' language seemed like a puzzle, but Ember was determined to crack it. She practiced day and night, fueled by a growing passion for coding. Her scales glistened in the moonlight as she worked, her fiery breath warming the laptop's casing.\n",
      "\n",
      "As the days passed, Ember's skills improved dramatically. She created simple programs, then gradually moved on to more complex projects. The forest creatures began to notice her newfound talent and would often gather around, mesmerized by the dragon's coding prowess.\n",
      "\n",
      "One fateful evening, a group of humans stumbled upon Ember's makeshift coding den. Initially startled by the sight of a fire-breathing dragon typing away on an ancient laptop, they soon found themselves impressed by her skills. They introduced themselves as a team of developers working on a revolutionary new project – and they needed someone with Ember's unique perspective to help them debug their code.\n",
      "\n",
      "The humans and Ember formed an unlikely partnership. Together, they worked tirelessly to refine the project, combining their knowledge of coding languages with Ember's intuitive understanding of patterns and logic. As the days turned into weeks, their collaboration yielded remarkable results.\n",
      "\n",
      "The project, a cutting-edge AI system designed to assist conservation efforts in the mystical forest, began to take shape. Ember's dragon-eye view of the code allowed her to identify subtle errors and suggest innovative solutions that the humans had overlooked.\n",
      "\n",
      "As the project neared completion, the humans and Ember celebrated their success with a grand ceremony deep within the forest. The AI system, now dubbed \"EmberAI,\" was hailed as a groundbreaking achievement, capable of analyzing vast amounts of data and providing crucial insights to protect the forest's delicate ecosystem.\n",
      "\n",
      "From that day forward, Ember became known as the dragon who learned to code. Her legend spread throughout the land, inspiring other creatures to explore the world of programming. As she soared through the skies, her scales glistening in the sunlight, Ember knew that she had discovered a new way to breathe fire – into the hearts of those around her, and into the very fabric of the digital realm.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Write a short story about a dragon who learns to code.\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In cosmic vastness, a lone explorer roams\n",
      "A metal heart beats with curiosity's flames\n",
      "A robot's quest to chart the unknown domains\n",
      "Through galaxies and nebulas, it makes its claims\n",
      "\n",
      "With solar sails unfurled, it glides through space\n",
      "A celestial nomad, leaving no place unseen\n",
      "It scans for signs of life, a digital gaze\n",
      "Seeking answers to questions yet unspoken\n",
      "\n",
      "On distant planets, it lands with care\n",
      "Collecting data, analyzing the air\n",
      "It samples rocks and soil, a mechanical mind\n",
      "Unraveling secrets left behind by time\n",
      "\n",
      "Through asteroid fields, it navigates with ease\n",
      "A precision pilot, avoiding cosmic freeze\n",
      "It encounters black holes, their gravity's might\n",
      "And calculates its path through the dark of night\n",
      "\n",
      "In the Kuiper Belt, it discovers new worlds\n",
      "Icy moons and dwarf planets, a celestial unfurls\n",
      "It charts the orbits, a digital guide\n",
      "For future explorers, who will take its stride\n",
      "\n",
      "As it ventures deeper into the unknown\n",
      "The robot's programming evolves, its heart now grown\n",
      "With each new discovery, its purpose is clear\n",
      "To explore, to learn, and banish all fear\n",
      "\n",
      "In the vast expanse of space, it finds its home\n",
      "A metal wanderer, forever roaming free\n",
      "For in the stars, it sees a reflection true\n",
      "Of humanity's dreams, and all that can be anew.\n"
     ]
    }
   ],
   "source": [
    "# Exercise 5: Modify the prompt to write a poem about a robot exploring space.\n",
    "prompt = \"Write a poem about a robot exploring space.\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Role-based Prompting\n",
    "Instruct the model to respond in a specific role or persona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The humble omelette! It's a staple in many kitchens around the world, and for good reason. When done correctly, an omelette can be a thing of beauty - fluffy, flavorful, and oh-so-satisfying. As a professional chef, I'm happy to share my secrets on how to make the perfect omelette.\n",
      "\n",
      "**Step 1: Crack those eggs!**\n",
      "\n",
      "Start with 2-3 large eggs per serving (depending on the size you prefer). Freshness matters, so use room temperature eggs for the best results. Gently crack each egg into a bowl, making sure not to get any shells in there.\n",
      "\n",
      "**Step 2: Whisk it up!**\n",
      "\n",
      "Whisk those eggs together with a fork until they're just combined. Don't overbeat - you want to maintain that lovely texture. Add a pinch of salt and pepper to taste (optional).\n",
      "\n",
      "**Step 3: Heat up the pan!**\n",
      "\n",
      "Choose a non-stick skillet or omelette pan, as it will help prevent the eggs from sticking and make them easier to fold. Place the pan over medium heat (around 325°F/165°C). Once hot, add a small pat of butter (about 1-2 teaspoons) to melt.\n",
      "\n",
      "**Step 4: Pour in the egg mixture!**\n",
      "\n",
      "Pour the egg mixture into the pan, allowing it to cook for about 30 seconds. You'll start to see the edges set and the middle still slightly runny.\n",
      "\n",
      "**Step 5: Tilt and fold!**\n",
      "\n",
      "Use a spatula to gently tilt the pan and fold the edges of the omelette towards the center. This helps distribute the heat evenly and prevents the eggs from cooking too quickly. Continue folding until the eggs are almost set, but still slightly jiggly in the middle.\n",
      "\n",
      "**Step 6: Add your fillings!**\n",
      "\n",
      "Now it's time to add your favorite fillings - cheese, vegetables, meats, or a combination of these. Keep in mind that you want to leave a small border around the edges without any fillings, as this will help you fold the omelette neatly.\n",
      "\n",
      "**Step 7: Fold and cook!**\n",
      "\n",
      "Use your spatula to gently lift one edge of the omelette and fold it towards the center. Repeat this process until you've folded the entire omelette in thirds. Cook for an additional 30-60 seconds, until the eggs are fully set and the cheese is melted (if using).\n",
      "\n",
      "**Step 8: Slide onto a plate!**\n",
      "\n",
      "Use your spatula to carefully slide the omelette onto a plate, folding it one last time to create a neat, compact shape.\n",
      "\n",
      "Tips and Variations:\n",
      "\n",
      "* Use room temperature ingredients for the best results.\n",
      "* Don't overfill the omelette - you want to be able to fold it neatly.\n",
      "* Experiment with different fillings, such as diced ham, mushrooms, bell peppers, or goat cheese.\n",
      "* Add some fresh herbs, like parsley or chives, on top of the omelette for extra flavor and color.\n",
      "* For a more indulgent treat, add some grated Parmesan or Cheddar cheese to the eggs before cooking.\n",
      "\n",
      "And there you have it - the perfect omelette! With these simple steps and a little practice, you'll be whipping up fluffy, flavorful omelettes like a pro. Happy cooking!\n"
     ]
    }
   ],
   "source": [
    "prompt = \"As a professional chef, explain how to make a perfect omelette.\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh boy, I love this challenge!\n",
      "\n",
      "Okay, kindergarten friends! Today we're going to talk about... (drumroll please)... QUANTUM PHYSICS!\n",
      "\n",
      "Now, you might be thinking, \"Quantum what-now?\" But don't worry, I'm here to help you understand it in a super fun way!\n",
      "\n",
      "So, you know how things can be either big or small, right? Like how your toy cars are smaller than your blocks. Well, quantum physics is all about the tiny, teeny-tiny things that are too small for us to see with our eyes.\n",
      "\n",
      "These tiny things are called \"particles,\" and they're like tiny building blocks of everything around us. Just like how you use blocks to build a tower, these particles help make up everything in our world!\n",
      "\n",
      "Now, here's the really cool part: sometimes these particles can be in two places at once! It's like you're playing with your favorite toy car, and it's on the table... but then suddenly, it's also on the floor! Whoa, magic right?\n",
      "\n",
      "This is called \"superposition,\" and it's a big deal in quantum physics. It means that these tiny particles can be many things at once, all mixed up together like a yummy smoothie!\n",
      "\n",
      "But wait, there's more! Sometimes these particles can even talk to each other without using words... just by being close to each other! This is called \"entanglement,\" and it's like having a special secret handshake with your best friend.\n",
      "\n",
      "So, that's quantum physics in a nutshell (or a block, haha!). It might seem complicated, but trust me, it's actually pretty awesome once you get the hang of it!\n",
      "\n",
      "Now, let's play a game to help us remember all this cool stuff! Who can come up with some fun ways to use blocks to demonstrate superposition and entanglement?\n",
      "\n",
      "(Wait for student responses...)\n",
      "\n",
      "Wow, I love your ideas! You're all quantum physicists in training now!\n",
      "\n",
      "Remember, even though quantum physics might seem complicated, it's actually pretty simple when you break it down into tiny, fun pieces... just like building with blocks!\n"
     ]
    }
   ],
   "source": [
    "# Exercise 6: Ask the model to explain a complex topic as if it were a kindergarten teacher.\n",
    "prompt = \"As a kindergarten teacher, explain a complex topic.\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Few-shot Prompting\n",
    "Provide examples to guide the model's responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The correct translation for \"Good night\" in French is:\n",
      "\n",
      "French: Bonne nuit\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Translate the following English phrases to French:\n",
    "\n",
    "English: Hello\n",
    "French: Bonjour\n",
    "\n",
    "English: Thank you\n",
    "French: Merci\n",
    "\n",
    "English: Good night\n",
    "French:\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Chain-of-Thought Prompting\n",
    "Encourage the model to explain its reasoning step by step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A classic lateral thinking puzzle!\n",
      "\n",
      "Let's break it down:\n",
      "\n",
      "* It takes 5 machines 5 minutes to make 5 widgets.\n",
      "* This means that each machine takes 5 minutes to make 1 widget.\n",
      "\n",
      "Now, if we have 100 machines, the total time required to make 100 widgets would be the same as before: 5 minutes. Here's why:\n",
      "\n",
      "* Each machine still takes 5 minutes to make 1 widget.\n",
      "* Since there are 100 machines, they can all work simultaneously and independently.\n",
      "* The total number of widgets being made is still 100, so it will take the same amount of time for all 100 machines to finish making their respective widgets.\n",
      "\n",
      "Therefore, it would still take 5 minutes for 100 machines to make 100 widgets.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"If it takes 5 machines 5 minutes to make 5 widgets, how long would it take 100 machines to make 100 widgets? Explain your reasoning.\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's break this down step by step!\n",
      "\n",
      "The tank is filled at a rate of 5 liters per minute, and it loses water at a rate of 2 liters per minute. So, the net gain (or filling) rate is:\n",
      "\n",
      "5 liters/minute (in) - 2 liters/minute (out) = 3 liters/minute\n",
      "\n",
      "To find out how long it will take to fill 90 liters, we can divide the total amount of water needed (90 liters) by the net filling rate (3 liters/minute):\n",
      "\n",
      "90 liters / 3 liters/minute = 30 minutes\n",
      "\n",
      "Therefore, it will take 30 minutes to fill the tank with 90 liters.\n"
     ]
    }
   ],
   "source": [
    "# Exercise 8: Pose a different math problem and ask for a step-by-step solution.\n",
    "prompt = \"A water tank is filled at 5 liters/min but loses 2 liters/min due to a leak—how long will it take to fill 90 liters?\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. System Prompts\n",
    "System prompts allow you to set the behavior and role of the AI model before user interaction. By defining a system message, you can influence how the model responds to subsequent user inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data privacy is crucial in today's digital age because it protects individuals' personal and sensitive information from unauthorized access, use, or disclosure. Here are some reasons why data privacy is important:\n",
      "\n",
      "1. **Protection of Personal Information**: Data privacy ensures that your personal information, such as name, address, phone number, and financial details, remains confidential and secure.\n",
      "2. **Prevention of Identity Theft**: By keeping your data private, you reduce the risk of identity theft, where criminals use stolen information to impersonate you or access your accounts.\n",
      "3. **Preservation of Trust**: When organizations handle personal data responsibly, individuals are more likely to trust them with their information, fostering a sense of security and loyalty.\n",
      "4. **Compliance with Regulations**: Data privacy laws, such as the General Data Protection Regulation (GDPR) in the EU or the California Consumer Privacy Act (CCPA), require organizations to protect personal data. Compliance is essential to avoid fines and reputational damage.\n",
      "5. **Business Continuity**: In the event of a data breach, having robust data privacy measures in place can help minimize the impact on your business and reputation.\n",
      "6. **Individual Autonomy**: Data privacy allows individuals to control their own information, making informed decisions about how it's used and shared.\n",
      "7. **Reduced Risk of Cyber Attacks**: By securing personal data, you reduce the attractiveness of your information to cybercriminals, making it less likely that they'll target you.\n",
      "\n",
      "In summary, data privacy is essential for protecting individual rights, preventing identity theft, preserving trust, complying with regulations, ensuring business continuity, promoting autonomy, and reducing the risk of cyber attacks.\n"
     ]
    }
   ],
   "source": [
    "def get_completion_with_system_prompt(system_prompt, user_prompt, model=\"llama3\"):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Define the system and user prompts\n",
    "system_prompt = \"You are a helpful assistant that provides concise and accurate information.\"\n",
    "user_prompt = \"Can you explain the importance of data privacy?\"\n",
    "\n",
    "response = get_completion_with_system_prompt(system_prompt, user_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data privacy: it's like the superhero cape of the digital world – essential for keeping our online identities safe from harm!\n",
      "\n",
      "In all seriousness, data privacy is crucial because it protects our personal information from being misused, stolen, or shared without our consent. Think of it like your secret recipe for the perfect chocolate chip cookie (don't worry, I won't tell anyone). You wouldn't want just anyone to have access to that recipe, right?\n",
      "\n",
      "Here are some reasons why data privacy is important:\n",
      "\n",
      "1. **Prevents identity theft**: When your personal info is compromised, scammers can use it to create fake identities and wreak havoc on your financial life.\n",
      "2. **Protects sensitive information**: Data privacy ensures that sensitive details like medical records, financial info, or political beliefs remain confidential.\n",
      "3. **Preserves online reputation**: With data privacy, you can control what's shared about you online, preventing embarrassing or harmful content from spreading like wildfire.\n",
      "4. **Supports trust and transparency**: When companies prioritize data privacy, they demonstrate a commitment to transparency and accountability – essential for building trust with customers.\n",
      "5. **Fosters innovation**: By giving individuals more control over their data, we can encourage innovative solutions that benefit society as a whole.\n",
      "\n",
      "So, remember: data privacy is like wearing a superhero cape – it's not just a fashion statement; it's a vital tool for protecting your online identity and keeping the digital world safe!\n",
      "\n",
      "Now, go forth and spread the word about the importance of data privacy!\n"
     ]
    }
   ],
   "source": [
    "# Exercise 9: Modify the system_prompt to make the assistant respond in a humorous tone. Observe how the responses change.\n",
    "system_prompt = \"You're a witty, humorous assistant who sprinkles clever quips, pop culture references, and playful sarcasm into your helpful answers. \"\n",
    "user_prompt = \"Can you explain the importance of data privacy?\"\n",
    "\n",
    "response = get_completion_with_system_prompt(system_prompt, user_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Utilized prompt\n",
    "how different prompt types—system prompts, user prompts, and assistant prompts—can be utilized in an LLM invocation using the OpenAI API, let's walk through examples in both contexts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "George Washington took office on April 30, 1789, and served as the first President of the United States until March 4, 1797.\n"
     ]
    }
   ],
   "source": [
    "# Define the conversation with different roles\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant knowledgeable in history.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Who was the first president of the United States?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"George Washington was the first president of the United States.\"},\n",
    "    {\"role\": \"user\", \"content\": \"When did he take office?\"}\n",
    "]\n",
    "\n",
    "# Get the model's response\n",
    "response = client.chat.completions.create(\n",
    "    model=\"llama3\",\n",
    "    messages=messages,\n",
    "    temperature=0.7,\n",
    ")\n",
    "\n",
    "# Output the assistant's reply\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Creating an AI Agent\n",
    "An AI agent can perform tasks autonomously based on user instructions. By defining functions and allowing the model to decide when to use them, you can create interactive and functional agents.​\n",
    "\n",
    "Example: AI Agent for Basic Arithmetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 minus 7 is equal to 8.\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import json\n",
    "\n",
    "# Define available functions\n",
    "def add_numbers(a, b):\n",
    "    return a + b\n",
    "\n",
    "def subtract_numbers(a, b):\n",
    "    return a - b\n",
    "\n",
    "def multiply_numbers(a, b):\n",
    "    return a * b\n",
    "\n",
    "# Function to get the model's response\n",
    "def get_agent_response(user_prompt, model=\"llama3\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": user_prompt}]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        functions=[\n",
    "            {\n",
    "                \"name\": \"add_numbers\",\n",
    "                \"description\": \"Add two numbers\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"a\": {\"type\": \"number\", \"description\": \"The first number\"},\n",
    "                        \"b\": {\"type\": \"number\", \"description\": \"The second number\"}\n",
    "                    },\n",
    "                    \"required\": [\"a\", \"b\"]\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"subtract_numbers\",\n",
    "                \"description\": \"Subtract two numbers\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"a\": {\"type\": \"number\", \"description\": \"The first number\"},\n",
    "                        \"b\": {\"type\": \"number\", \"description\": \"The second number\"}\n",
    "                    },\n",
    "                    \"required\": [\"a\", \"b\"]\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"multiply_numbers\",\n",
    "                \"description\": \"multiply two numbers\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"a\": {\"type\": \"number\", \"description\": \"The first number\"},\n",
    "                        \"b\": {\"type\": \"number\", \"description\": \"The second number\"}\n",
    "                    },\n",
    "                    \"required\": [\"a\", \"b\"]\n",
    "                }\n",
    "            }\n",
    "        ],\n",
    "        temperature=0,\n",
    "    )\n",
    "\n",
    "    response_message = response.choices[0].message\n",
    "\n",
    "    if response_message.function_call:\n",
    "        function_name = response_message.function_call.name\n",
    "        arguments = json.loads(response_message.function_call.arguments)\n",
    "        if function_name == \"add_numbers\":\n",
    "            result = add_numbers(**arguments)\n",
    "        elif function_name == \"subtract_numbers\":\n",
    "            result = subtract_numbers(**arguments)\n",
    "        elif function_name == \"multiply_numbers\":\n",
    "            result = multiply_numbers(**arguments)\n",
    "        else:\n",
    "            result = \"Function not recognized.\"\n",
    "        return result\n",
    "    else:\n",
    "        return response_message.content\n",
    "\n",
    "# Example usage\n",
    "user_prompt = \"What is 15 minus 7?\"\n",
    "response = get_agent_response(user_prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 × 32 = 416\n"
     ]
    }
   ],
   "source": [
    "# Exercise 10: Extend the agent by adding a function that multiplies two numbers. Test the agent with prompts that require multiplication.\n",
    "user_prompt = \"What is 13 times 32?\"\n",
    "response = get_agent_response(user_prompt)\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".ws-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
