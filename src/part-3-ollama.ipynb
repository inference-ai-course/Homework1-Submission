{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3\n",
    "\n",
    "\n",
    "The module 1 lecture example  didn't use langchain for orchestration.\n",
    "\n",
    "\n",
    "Tasks:\n",
    "\n",
    "- Basic prompting (What is the capital of France)\n",
    "- Summarization - Summarizing an example text\n",
    "- Information extraction - Getting information from a prompt\n",
    "- Transformation - Translating a text, for example.\n",
    "- Expansion or generative - Expanding a prompt into a more detailed response. e.g. Write a short story about the red planet, mars.\n",
    "- Role based prompting - Instructing a model to respond in a specific persona\n",
    "- Few shot prompting - giving the model examples int he prompt.\n",
    "- chain of thought prompting - encouraging the model to reason out its steps.\n",
    "- system prompts - setting out the behavior and the role of the ai model before user interaction\n",
    "- utilized prompt - give the llm an example of both contexts: system, user assistant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the conda environment with a default python\n",
    "#! conda create -n hw-1-submission python=3.11\n",
    "\n",
    "# activate the conda environment\n",
    "#! conda activate myenv \n",
    "\n",
    "# make sure you have a conda envornment, and have added the conda-forge channel.\n",
    "#! conda install --name hw-1-submission  openai "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AI Agent\n",
    "\n",
    "Uses:\n",
    "\n",
    "- Ollama (local) - smollm:1.7b because it is lightweight.\n",
    "- Open AI Python Library\n",
    "- Has two tools: add_numbers and subtract_numbers\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The answer is 6.\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import json\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "client = openai.OpenAI(\n",
    "    base_url = 'http://localhost:11434/v1',\n",
    "    api_key='ollama', # required, but unused\n",
    ")\n",
    "\n",
    "# Define available functions\n",
    "def add_numbers(a, b):\n",
    "    return a + b\n",
    "\n",
    "def subtract_numbers(a, b):\n",
    "    return a - b\n",
    "\n",
    "# Function to get the model's response\n",
    "def get_agent_response(user_prompt, model=\"smollm2:1.7b\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": user_prompt}]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        functions=[\n",
    "            {\n",
    "                \"name\": \"add_numbers\",\n",
    "                \"description\": \"Add two numbers\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"a\": {\"type\": \"number\", \"description\": \"The first number\"},\n",
    "                        \"b\": {\"type\": \"number\", \"description\": \"The second number\"}\n",
    "                    },\n",
    "                    \"required\": [\"a\", \"b\"]\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"subtract_numbers\",\n",
    "                \"description\": \"Subtract two numbers\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"a\": {\"type\": \"number\", \"description\": \"The first number\"},\n",
    "                        \"b\": {\"type\": \"number\", \"description\": \"The second number\"}\n",
    "                    },\n",
    "                    \"required\": [\"a\", \"b\"]\n",
    "                }\n",
    "            }\n",
    "        ],\n",
    "        temperature=0,\n",
    "    )\n",
    "\n",
    "    response_message = response.choices[0].message\n",
    "\n",
    "    if response_message.function_call:\n",
    "        function_name = response_message.function_call.name\n",
    "        arguments = json.loads(response_message.function_call.arguments)\n",
    "        if function_name == \"add_numbers\":\n",
    "            result = add_numbers(**arguments)\n",
    "        elif function_name == \"subtract_numbers\":\n",
    "            result = subtract_numbers(**arguments)\n",
    "        else:\n",
    "            result = \"Function not recognized.\"\n",
    "        return result\n",
    "    else:\n",
    "        return response_message.content\n",
    "\n",
    "# Example usage\n",
    "user_prompt = \"What is 15 minus 7?\"\n",
    "response = get_agent_response(user_prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;32m2\u001b[0m\u001b[1;32m channel Terms of Service accepted\u001b[0m\n",
      "Channels:\n",
      " - conda-forge\n",
      " - defaults\n",
      "Platform: linux-64\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "    current version: 25.5.1\n",
      "    latest version: 25.9.1\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/iankt/anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - langchain\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    async-timeout-4.0.3        |     pyhd8ed1ab_0          11 KB  conda-forge\n",
      "    conda-25.7.0               |  py313h78bf25f_0         1.2 MB  conda-forge\n",
      "    langchain-1.0.2            |pymin313_h332efcf_0          86 KB  conda-forge\n",
      "    langchain-core-1.0.1       |     pyhd8ed1ab_0         298 KB  conda-forge\n",
      "    langchain-text-splitters-0.3.11|     pyhd8ed1ab_0          33 KB  conda-forge\n",
      "    langgraph-1.0.1            |     pyhd8ed1ab_0         113 KB  conda-forge\n",
      "    langgraph-checkpoint-3.0.0 |     pyhcf101f3_0          43 KB  conda-forge\n",
      "    langgraph-prebuilt-1.0.1   |     pyhcf101f3_0          32 KB  conda-forge\n",
      "    langgraph-sdk-0.2.9        |     pyhcf101f3_0          46 KB  conda-forge\n",
      "    langsmith-0.3.45           |     pyhd8ed1ab_1         294 KB  conda-forge\n",
      "    orjson-3.11.4              |  py313h843e2db_0         309 KB  conda-forge\n",
      "    ormsgpack-1.11.0           |  py313h8b35106_1         221 KB  conda-forge\n",
      "    python-xxhash-3.6.0        |  py313heab5758_0          23 KB  conda-forge\n",
      "    xxhash-0.8.3               |       hb47aa4a_0         106 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         2.8 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  async-timeout      conda-forge/noarch::async-timeout-4.0.3-pyhd8ed1ab_0 \n",
      "  langchain          conda-forge/noarch::langchain-1.0.2-pymin313_h332efcf_0 \n",
      "  langchain-core     conda-forge/noarch::langchain-core-1.0.1-pyhd8ed1ab_0 \n",
      "  langchain-text-sp~ conda-forge/noarch::langchain-text-splitters-0.3.11-pyhd8ed1ab_0 \n",
      "  langgraph          conda-forge/noarch::langgraph-1.0.1-pyhd8ed1ab_0 \n",
      "  langgraph-checkpo~ conda-forge/noarch::langgraph-checkpoint-3.0.0-pyhcf101f3_0 \n",
      "  langgraph-prebuilt conda-forge/noarch::langgraph-prebuilt-1.0.1-pyhcf101f3_0 \n",
      "  langgraph-sdk      conda-forge/noarch::langgraph-sdk-0.2.9-pyhcf101f3_0 \n",
      "  langsmith          conda-forge/noarch::langsmith-0.3.45-pyhd8ed1ab_1 \n",
      "  libgcc             conda-forge/linux-64::libgcc-15.2.0-h767d61c_7 \n",
      "  orjson             conda-forge/linux-64::orjson-3.11.4-py313h843e2db_0 \n",
      "  ormsgpack          conda-forge/linux-64::ormsgpack-1.11.0-py313h8b35106_1 \n",
      "  python-xxhash      conda-forge/linux-64::python-xxhash-3.6.0-py313heab5758_0 \n",
      "  xxhash             conda-forge/linux-64::xxhash-0.8.3-hb47aa4a_0 \n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  ca-certificates    pkgs/main/linux-64::ca-certificates-2~ --> conda-forge/noarch::ca-certificates-2025.10.5-hbd8a1cb_0 \n",
      "  conda              pkgs/main::conda-25.5.1-py313h06a4308~ --> conda-forge::conda-25.7.0-py313h78bf25f_0 \n",
      "  libgcc-ng          pkgs/main::libgcc-ng-11.2.0-h1234567_1 --> conda-forge::libgcc-ng-15.2.0-h69a702a_7 \n",
      "  libgomp              pkgs/main::libgomp-11.2.0-h1234567_1 --> conda-forge::libgomp-15.2.0-h767d61c_7 \n",
      "  openssl              pkgs/main::openssl-3.0.18-hd6dcaed_0 --> conda-forge::openssl-3.5.4-h26f9b46_0 \n",
      "  pip                      pkgs/main::pip-25.1-pyhc872135_2 --> conda-forge::pip-25.2-pyh145f28c_0 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages:\n",
      "conda-25.7.0         | 1.2 MB    |                                       |   0% \n",
      "orjson-3.11.4        | 309 KB    |                                       |   0% \u001b[A\n",
      "\n",
      "langchain-core-1.0.1 | 298 KB    |                                       |   0% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "langsmith-0.3.45     | 294 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "ormsgpack-1.11.0     | 221 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "langgraph-1.0.1      | 113 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "xxhash-0.8.3         | 106 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "langchain-1.0.2      | 86 KB     |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "langgraph-sdk-0.2.9  | 46 KB     |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "langgraph-checkpoint | 43 KB     |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "langchain-text-split | 33 KB     |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "langgraph-prebuilt-1 | 32 KB     |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "python-xxhash-3.6.0  | 23 KB     |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "async-timeout-4.0.3  | 11 KB     |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "conda-25.7.0         | 1.2 MB    | 4                                     |   1% \u001b[A\u001b[A\u001b[A\n",
      "orjson-3.11.4        | 309 KB    | #9                                    |   5% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "ormsgpack-1.11.0     | 221 KB    | ##6                                   |   7% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "langsmith-0.3.45     | 294 KB    | ####################################2 |  98% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "langchain-core-1.0.1 | 298 KB    | #9                                    |   5% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "conda-25.7.0         | 1.2 MB    | ######3                               |  17% \u001b[A\u001b[A\u001b[A\n",
      "orjson-3.11.4        | 309 KB    | #################2                    |  47% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "conda-25.7.0         | 1.2 MB    | #################6                    |  48% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "langsmith-0.3.45     | 294 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "ormsgpack-1.11.0     | 221 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "orjson-3.11.4        | 309 KB    | ##################################### | 100% \u001b[A\n",
      "\n",
      "langchain-core-1.0.1 | 298 KB    | ###############8                      |  43% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "langgraph-1.0.1      | 113 KB    | #####2                                |  14% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "langgraph-1.0.1      | 113 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "conda-25.7.0         | 1.2 MB    | ####################################6 |  99% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "conda-25.7.0         | 1.2 MB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "xxhash-0.8.3         | 106 KB    | #####6                                |  15% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "xxhash-0.8.3         | 106 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "orjson-3.11.4        | 309 KB    | ##################################### | 100% \u001b[A\n",
      "orjson-3.11.4        | 309 KB    | ##################################### | 100% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "langgraph-checkpoint | 43 KB     | #############6                        |  37% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "langchain-1.0.2      | 86 KB     | ######9                               |  19% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "langgraph-checkpoint | 43 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "langchain-text-split | 33 KB     | #################8                    |  48% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "langchain-1.0.2      | 86 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "langchain-text-split | 33 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "langgraph-sdk-0.2.9  | 46 KB     | ############8                         |  35% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "langgraph-prebuilt-1 | 32 KB     | ##################5                   |  50% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "langgraph-prebuilt-1 | 32 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "langgraph-sdk-0.2.9  | 46 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "langgraph-1.0.1      | 113 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "python-xxhash-3.6.0  | 23 KB     | #########################4            |  69% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "langgraph-1.0.1      | 113 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "python-xxhash-3.6.0  | 23 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "async-timeout-4.0.3  | 11 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "async-timeout-4.0.3  | 11 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "xxhash-0.8.3         | 106 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "xxhash-0.8.3         | 106 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "langgraph-checkpoint | 43 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "langgraph-checkpoint | 43 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "langchain-core-1.0.1 | 298 KB    | ##################################### | 100% \u001b[A\u001b[A\n",
      "\n",
      "langchain-core-1.0.1 | 298 KB    | ##################################### | 100% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "langchain-1.0.2      | 86 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "langchain-1.0.2      | 86 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "langgraph-prebuilt-1 | 32 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "langgraph-prebuilt-1 | 32 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "langchain-text-split | 33 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "langchain-text-split | 33 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "langgraph-sdk-0.2.9  | 46 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "langgraph-sdk-0.2.9  | 46 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "python-xxhash-3.6.0  | 23 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "python-xxhash-3.6.0  | 23 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n"
     ]
    }
   ],
   "source": [
    "## Lets use langchain\n",
    "! conda install langchain -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='what is the weather in Nairobi?' additional_kwargs={} response_metadata={} id='b9b7151c-dcd5-4fb1-aa61-e6c80881a01d'\n",
      "content='' additional_kwargs={} response_metadata={'model': 'smollm2:1.7b', 'created_at': '2025-10-29T04:13:14.023824809Z', 'done': True, 'done_reason': 'stop', 'total_duration': 1812561362, 'load_duration': 43598220, 'prompt_eval_count': 316, 'prompt_eval_duration': 80669311, 'eval_count': 32, 'eval_duration': 1667989691, 'model_name': 'smollm2:1.7b', 'model_provider': 'ollama'} id='lc_run--13e4ccc5-4588-48e7-9a39-ae0e95bb7825-0' tool_calls=[{'name': 'get_weather', 'args': {'city': 'Nairobi'}, 'id': '12a7ec49-676e-4b03-bd23-0df39b5f5a28', 'type': 'tool_call'}] usage_metadata={'input_tokens': 316, 'output_tokens': 32, 'total_tokens': 348}\n",
      "content=\"It's always sunny in Nairobi\" name='get_weather' id='62dff961-c6f0-4fce-96a5-c050fcea4ac9' tool_call_id='12a7ec49-676e-4b03-bd23-0df39b5f5a28'\n",
      "content='The output should not be provided as it does not match the format specified. The function call is correct though.' additional_kwargs={} response_metadata={'model': 'smollm2:1.7b', 'created_at': '2025-10-29T04:13:16.205033758Z', 'done': True, 'done_reason': 'stop', 'total_duration': 2172262811, 'load_duration': 36025690, 'prompt_eval_count': 377, 'prompt_eval_duration': 993188832, 'eval_count': 23, 'eval_duration': 1126122752, 'model_name': 'smollm2:1.7b', 'model_provider': 'ollama'} id='lc_run--61b146e9-fc1a-411b-a8b6-1bdf5b63edcb-0' usage_metadata={'input_tokens': 377, 'output_tokens': 23, 'total_tokens': 400}\n"
     ]
    }
   ],
   "source": [
    "# create an agent\n",
    "from langchain.agents import create_agent\n",
    "from langchain_ollama import ChatOllama\n",
    "import time\n",
    "\n",
    "# large language model\n",
    "llm = ChatOllama(\n",
    "    model=\"smollm2:1.7b\",\n",
    "    temperature=1\n",
    ")\n",
    "\n",
    "# tool to get weather information\n",
    "def get_weather(city: str)->str:\n",
    "    \"\"\"Get weather for a given city.\"\"\"\n",
    "    return f\"It's always sunny in {city}\"\n",
    "\n",
    "def get_time(city: str)->str:\n",
    "    \"\"\"Gets the current local time\"\"\"\n",
    "    current_time = time.strftime(\"%H:%M:%S\", time.localtime())\n",
    "    return f\"Current time:{current_time}\"\n",
    "\n",
    "\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=[get_weather, get_time],\n",
    "    system_prompt=\"You are a helpful assistant.\"\n",
    ")\n",
    "\n",
    "\n",
    "# all the agent\n",
    "results = agent.invoke(\n",
    "    {\"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\":\"what is the weather in Nairobi?\"\n",
    "        }\n",
    "    ]}\n",
    ")\n",
    "\n",
    "for r in results[\"messages\"]:\n",
    "    print(f\"{r}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='What is the current time there?' additional_kwargs={} response_metadata={} id='bd0a02eb-0354-45f9-ba39-2b1eaffbffab'\n",
      "content='' additional_kwargs={} response_metadata={'model': 'smollm2:1.7b', 'created_at': '2025-10-29T04:13:49.409323215Z', 'done': True, 'done_reason': 'stop', 'total_duration': 1806466308, 'load_duration': 89317852, 'prompt_eval_count': 316, 'prompt_eval_duration': 456107400, 'eval_count': 25, 'eval_duration': 1239799059, 'model_name': 'smollm2:1.7b', 'model_provider': 'ollama'} id='lc_run--b82a85f1-09ba-4418-81ed-fffb60dcdd98-0' tool_calls=[{'name': 'get_time', 'args': {}, 'id': '673679af-758f-4c5b-9ac1-51acf087a62a', 'type': 'tool_call'}] usage_metadata={'input_tokens': 316, 'output_tokens': 25, 'total_tokens': 341}\n",
      "content='Current time:21:13:49' name='get_time' id='f947183f-9eb2-4dc9-a3d8-1822dd0c7a18' tool_call_id='673679af-758f-4c5b-9ac1-51acf087a62a'\n",
      "content='The output contains a tool response with the current time in 24-hour format.' additional_kwargs={} response_metadata={'model': 'smollm2:1.7b', 'created_at': '2025-10-29T04:13:51.326820363Z', 'done': True, 'done_reason': 'stop', 'total_duration': 1911233148, 'load_duration': 25156387, 'prompt_eval_count': 377, 'prompt_eval_duration': 955941393, 'eval_count': 19, 'eval_duration': 916363121, 'model_name': 'smollm2:1.7b', 'model_provider': 'ollama'} id='lc_run--df844234-1cd6-47e6-bb57-8d14a2149a8b-0' usage_metadata={'input_tokens': 377, 'output_tokens': 19, 'total_tokens': 396}\n"
     ]
    }
   ],
   "source": [
    "results = agent.invoke(\n",
    "    {\"messages\" :[\n",
    "        {\n",
    "            \"role\":\"user\",\n",
    "            \"content\":\"What is the current time there?\"}\n",
    "    ]}\n",
    ")\n",
    "for r in results[\"messages\"]:\n",
    "    print(f\"{r}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"The capital city of Ethiopia is Addis Ababa. Currently, it's 7:30 AM EST. As for the weather, it typically enjoys a temperate climate with average temperatures ranging from 55째F (13째C) to 68째F (20째C), depending on whether it's in the northern or southern parts of Ethiopia.\", additional_kwargs={}, response_metadata={'model': 'smollm2:1.7b', 'created_at': '2025-10-29T04:38:43.827616611Z', 'done': True, 'done_reason': 'stop', 'total_duration': 14230994839, 'load_duration': 9595503548, 'prompt_eval_count': 45, 'prompt_eval_duration': 835114168, 'eval_count': 77, 'eval_duration': 3735432755, 'model_name': 'smollm2:1.7b', 'model_provider': 'ollama'}, id='lc_run--56b52755-3fc8-42d1-9869-25761a960a74-0', usage_metadata={'input_tokens': 45, 'output_tokens': 77, 'total_tokens': 122})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"What is the capital city of Ethiopia? What is the time and weather there?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='What is the capital city of Ethiopia? What is the time and weather there?' additional_kwargs={} response_metadata={} id='7d7fff9e-d79c-4977-9d09-1a3cdb1ff8c7'\n",
      "content='' additional_kwargs={} response_metadata={'model': 'smollm2:1.7b', 'created_at': '2025-10-29T04:40:59.94781555Z', 'done': True, 'done_reason': 'stop', 'total_duration': 7041104435, 'load_duration': 106885253, 'prompt_eval_count': 325, 'prompt_eval_duration': 4618059238, 'eval_count': 46, 'eval_duration': 2269557249, 'model_name': 'smollm2:1.7b', 'model_provider': 'ollama'} id='lc_run--a73863f2-7103-42be-8aee-0bf197e5ffe2-0' tool_calls=[{'name': 'get_weather', 'args': {'city': 'Addis Ababa'}, 'id': '199ed493-4820-45a0-96ab-04c64671034a', 'type': 'tool_call'}, {'name': 'get_time', 'args': {}, 'id': 'f7238ec1-6fd0-42c4-9975-8c1c2bd33bfd', 'type': 'tool_call'}] usage_metadata={'input_tokens': 325, 'output_tokens': 46, 'total_tokens': 371}\n",
      "content=\"It's always sunny in Addis Ababa\" name='get_weather' id='9563ef5d-8a93-4021-a519-c04356952979' tool_call_id='199ed493-4820-45a0-96ab-04c64671034a'\n",
      "content='Current time:21:40:59' name='get_time' id='1fc0bb12-98f0-4c53-880c-e3f5044f1684' tool_call_id='f7238ec1-6fd0-42c4-9975-8c1c2bd33bfd'\n",
      "content=\"The output must strictly adhere to the format as specified. Since the response is not formatted according to that format, a new format will be provided below:\\n\\nResponse:\\nIt's always sunny in Addis Ababa\\n\\nCurrent time:21:40:59\" additional_kwargs={} response_metadata={'model': 'smollm2:1.7b', 'created_at': '2025-10-29T04:41:04.705316998Z', 'done': True, 'done_reason': 'stop', 'total_duration': 4737133982, 'load_duration': 35503323, 'prompt_eval_count': 432, 'prompt_eval_duration': 1747273005, 'eval_count': 58, 'eval_duration': 2906401897, 'model_name': 'smollm2:1.7b', 'model_provider': 'ollama'} id='lc_run--8c9afe6b-9039-41a5-a6f0-92b0dda9dc09-0' usage_metadata={'input_tokens': 432, 'output_tokens': 58, 'total_tokens': 490}\n"
     ]
    }
   ],
   "source": [
    "results = agent.invoke(\n",
    "    {\"messages\" :[\n",
    "        {\n",
    "            \"role\":\"user\",\n",
    "            \"content\":\"What is the capital city of Ethiopia? What is the time and weather there?\"}\n",
    "    ]}\n",
    ")\n",
    "for r in results[\"messages\"]:\n",
    "    print(f\"{r}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
